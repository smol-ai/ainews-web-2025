---
id: 2eb6174b-42f8-4774-9356-7d4ae4b2db99
title: AI Discords Newsletter  11/30/2023
date: '2023-11-30T20:09:26.563196Z'
original_slug: ainews-ai-discords-newsletter-11302023
description: >-
  AI community discussions and updates including AI prompts, Discord recaps,
  Stability AI developments, Payball bypass, Reddit activity, podcast
  announcement, academic papers, OpenAI updates, AI in mining, quantum
  computing, education, coding tools, and hardware performance.
companies:
  - openai
  - stability-ai
models: []
topics:
  - ai-prompts
  - discords
  - industry-developments
  - stability-ai
  - payball-bypass
  - reddit-activity
  - podcast
  - academic-papers
  - openai
  - ai-in-mining
  - quantum-computing
  - education
  - coding-tools
  - hardware-performance
---


<!-- buttondown-editor-mode: plaintext -->
## [Latent Space](https://discord.com/channels/822583790773862470) Discord Summary

- Sharing of AI tools and resources for feedback and learning, including **AI Prompts by Guardiang** and **AI Discords Recap by Swyxio**:
    - [guardiang's prompt tool](https://chat.openai.com/g/g-lfTjssx7f-omni-s-prompts)
    - [AI Discords newsletter](https://buttondown.email/ainews/archive/ainews-ai-discords-newsletter-11292023/)
- Active discussion on recent industry developments, focusing on entities like **Stability AI** and *Payball*:
    - Information about Stability AI being pressured to change the CEO [source](https://www.bloomberg.com/news/articles/2023-11-29/stability-ai-has-explored-sale-as-investor-urges-ceo-to-resign), 
    - An issue about Payball bypass [source](https://archive.ph/M3rri)
- Exploration of community members' activities, with a focus on a Reddit user, **Emad**:
    - Emad's Reddit profile [source](https://www.reddit.com/user/emad_9608/)
    - Emad's damage control comment on Reddit [source](https://www.reddit.com/r/StableDiffusion/comments/186rwji/comment/kbalfk7/?context=3)
- Announcement of a new episode for the *Latent Space Podcast*
    - [Twitter announcement link](https://twitter.com/latentspacepod/status/1729974854290665845)
- In the academic scene, conversation points included an inquiry about a **Context Reversal paper** and requests for an updated **list of covered papers** in the **llm-paper-club** channel, demonstrating a proactive and studious community.

**Latent Space Channel Summaries**

### ‚ñ∑ Channel: [ai-general-chat](https://discord.com/channels/822583790773862470/1075282825051385876) (11 messages): 

- **AI Prompts by Guardiang**: `@guardiang` shared a prompt tool and invited feedback, linking to the tool at [chat.openai.com](https://chat.openai.com/g/g-lfTjssx7f-omni-s-prompts).
- **AI Discords Recap by Swyxio**: `@swyxio` shared a link to a newsletter collating recent news and discussions from AI-related Discord channels, available at [buttondown.email](https://buttondown.email/ainews/archive/ainews-ai-discords-newsletter-11292023/).
- **Stability AI Developments by Swyxio**: `@swyxio` pointed out recent developments surrounding Stability AI, including investor pressure for the CEO to resign. The news is published in a [Bloomberg article](https://www.bloomberg.com/news/articles/2023-11-29/stability-ai-has-explored-sale-as-investor-urges-ceo-to-resign).
- **Payball Bypass shared by Jevonm**: `@jevonm` shared a link to an [archived article](https://archive.ph/M3rri) concerning the Payball bypass issue.
- **Chat on Emad's Reddit Activity by Coffeebean6887**: `@coffeebean6887` noted Emad's recent Reddit comments, providing links to both his [Reddit profile](https://www.reddit.com/user/emad_9608/) and a specific [damage control comment](https://www.reddit.com/r/StableDiffusion/comments/186rwji/comment/kbalfk7/?context=3) he made.


### ‚ñ∑ Channel: [ai-event-announcements](https://discord.com/channels/822583790773862470/1075282504648511499) (1 messages): 

- **Latent Space Podcast Announcement**: User `@swyxio` announced that a new podcast has gone live and shared a [link](https://twitter.com/latentspacepod/status/1729974854290665845) to the announcement made on **Twitter**.


### ‚ñ∑ Channel: [llm-paper-club](https://discord.com/channels/822583790773862470/1107320650961518663) (3 messages): 

- **Chain of Note paper club notes**: User `@swyxio` mentioned the topic of **Note paper club notes**.
- **Context Reversal Paper**: User `@yikesawjeez` asked for the title of a specific **Context Reversal paper**.
- **List of Covered Papers**: User `@zf0` inquired about the existence of an **updated list of the already covered papers**, noting that the current spreadsheet might be outdated.


        

---

## [OpenAI](https://discord.com/channels/974519864045756446) Discord Summary

- Announcement about an update from OpenAI, shared by user `@abdubs` on the OpenAI Twitter account.
- In-depth conversation about the use of AI models in facilitating mining exploration reports; `@rjkmelb` shared success stories of having such service adopted by seven companies.
- Animated debates about the potential impact of AI and quantum computing on future technology; the conversation showed divergent estimates about when quantum computing will enter commercial space.
- Exploration of the role of AI in education, especially of ChatGPT. Mixed views surfaced concerning whether AI-assisted productivity tools in education should be considered "cheating". 
- Engaged discussions around the usefulness of AI in coding, with GitHub Copilot as the central subject. The dialogue presented contrasting views on its pros and cons.
- Conversations on the performance of Local Language Models (LLMs) on different hardware setups. Apple Mac M series chips with a good amount of RAM was identified as the preferred option.
- Commemoration of ChatGPT's one-year anniversary, reflecting on its utility and potential for enhancing learning and problem-solving.
- Concerns expressed about OpenAI's usage policies, suggesting the need for higher-cost, unlimited usage plans for heavy users, and inquiries about the perceived degradation of the core model via the web app.
- Discussions on multi-user chats and visual integration potential, introduced by users `@thetruth3130` and `@rewire`.
- Anticipation and speculation about future OpenAI releases and management changes, with topics ranging from the release of GPT-5 to potential Quantum Computing integration.
- Clarification about some issues like DNS propagation, issues with GPT-4 providing text instead of solutions, problems with age verification system, GPT usage on desktop, authentication configuration for OpenAI, and several billing issues.
- Introduction of various Custom GPT, prompting techniques, and discussions regarding issues and solutions related to GPT-4.
- Discussions of prompt engineering techniques, experiences with GPT-3, methods for outcome generation, and processes for identifying and resolving conflicts. Users `@madame_architect`, `@exh0rt`, and `@eskcanta` actively participated in sharing insights and suggestions.

**OpenAI Channel Summaries**

### ‚ñ∑ Channel: [annnouncements](https://discord.com/channels/974519864045756446/977259063052234752) (1 messages): 

- **OpenAI Twitter Update**: `@abdubs` shared an [update from OpenAI](https://fxtwitter.com/OpenAI/status/1730030975931846939?s=20).


### ‚ñ∑ Channel: [ai-discussions](https://discord.com/channels/974519864045756446/998381918976479273) (262 messagesüî•): 

- **Use of AI in Mining Exploration Reports**: User `@rjkmelb` shared their successful implementation of using a AI model to read old geotechnical mining exploration reports and simplify them for non-technical researchers. This solution is employed by seven companies that pay around $1200 AUD per month to use it. There's a plan to scale the service to potential prospectors too. 
- **Discussions on AI & Quantum Computing**: Users debated the future of AI, predicting a significant acceleration in technological advancement, particularly in relation to quantum computing. While some argue that quantum computing will enter the commercial space in the next 10 years, others believe its commercial viability is still decades away.
- **The Role of AI in Education**: Users discussed the role of AI in education, especially the use of ChatGPT as a tool for students. Some argue that it should be treated like any other tool that enhances productivity and should not be considered "cheating", others voice concerns about students potentially using AI to bypass learning and understanding critical course content.
- **Value of AI in Coding**: Participants debated the usefulness of AI in coding, particularly the application of GitHub copilot. Some users find caution in its application due to its drawbacks while proponents argue about its value as a productivity multiplier, but only in the hands of those with domain knowledge.
- **Discussion on Local Language Models (LLMs)**: `@thewizzard___` and `@rjkmelb` discussed using local LLMs on different hardware setups. They noted that Apple Mac M series chips with a good amount of RAM performs very well for this task as opposed to a PC setup.


### ‚ñ∑ Channel: [openai-chatter](https://discord.com/channels/974519864045756446/977697652147892304) (672 messagesüî•): 

- **ChatGPT's Birthday and Relevance in Personal Development:** Users celebrated ChatGPT's one-year anniversary, expressing their appreciation of the tool's utility and potential for enhancing learning and solving problems. User `@mysticmarks1` referred to using the tool for prompting complex neural network models, while `@dyhr` used it for code optimization (source: <https://chat.openai.com>).
- **Discussion on Use of AI in Education:** Users debated the role of AI, particularly ChatGPT, in completing schoolwork. Potential misuse of the tool for cheating was discussed, with concerns raised about if (and how) rules against such usage could realistically be enforced (source: <https://chat.openai.com>).
- **Concerns about OpenAI's Policy and ChatGPT Limitations:** Some users expressed frustration about policies on limiting model usage and code generation. Discussions revolved around whether it would make sense to have higher-cost, unlimited usage plans for heavy users. There were also concerns about the perceived degradation of the core model via the web app and a request for public clarification (source: <https://chat.openai.com>).
- **Potential of Multi-user Chats and Visual Integration:** Users `@thetruth3130` and `@rewire` inquired about the possibility of having multiple active users in a chat and the potential integration of image upload while using a plugin, respectively (source: <https://chat.openai.com>).
- **Anticipation of Future OpenAI Announcements:** Speculation and anticipation were high among users for future OpenAI releases and changes in company management. The topics ranged from the release of GPT-5 to changes in company leadership and the potential for Quantum Computing integration (source: <https://chat.openai.com>).


### ‚ñ∑ Channel: [openai-questions](https://discord.com/channels/974519864045756446/974519864045756454) (120 messages): 

- **DNS Propagation Issue**: `@zero1.ai` asked if anyone faced issues with DNS propagation after adding TXT record to their domain. 
- **Issues with GPT-4 Providing Text Instead of Solutions**: `@selekcjoner.` expressed frustration with **GPT-4's** inability to solve problems directly and its tendency to generate extensive text. `@elektronisade` responded that this was a known bug which OpenAI is working on. `@selekcjoner.` suggested allowing usage of older GPT versions as a quick fix.
- **Age Verification System**: `@memenorio` discussed receiving an email notification about an age verification system from OpenAI. The notification was confirmed as legitimate following a link provided in the email.
- **Issues with GPT Usage on Desktop**: `@apelambo` reported having problems running the GPT on his desktop, both on Chrome and Brave browsers. `@solbus` suggested trying Firefox and inquired about the use of a VPN. Disabling the VPN appeared to fix the issue.
- **Discussion on Propagation of Code Errors**: `@woodenrobot` shared issues of a circular dependency in a yaml code causing errors despite commenting out every reference. The issue persists and further discussion was suggested in another channel.
- **Discussion on GPT-4 Waitlist and Subscription**: There were numerous discussions about the wait time for GPT-4, subscription issues, payment methods, and usage limitations. Users expressed concern regarding these issues but no definitive answers were provided.
- **Issues with Rough Drafts and GPT Upgrades**: `@a_chepurnyi` expressed disappointment after losing a month-long chat while trying to write a novel using GPT. It switched from version 4 to version 3.5 after exceeding the message limit. `@solbus` confirmed that there is no option to revert back to version 4 once switched to 3.5, and suggested starting a new chat with copied content certain points from the older chat.
- **Auth Configuration for OpenAI**: `@rosarioemmi` was having troubles configuring Auth for OpenAI, and asked for help. No specific solution was offered in the channel. 
- **OpenAI API Questions**: Discussion on consuming the OpenAI API, encountered errors, and rate limits was orchestrated by users including `@pandaterminator`, `@rudrajadaun_09`, and `@bombenstein`. Various solutions and tips are offered by the community. 
- **Billing Help**: `@coddent` expressed frustration over unresolved billing issues with OpenAI's API access and the customer support's inability to assist appropriately. No specific answers were offered.


### ‚ñ∑ Channel: [gpt-4-discussions](https://discord.com/channels/974519864045756446/1001151820170801244) (66 messages): 

- **GPT-4 Discussion Highlights**:
    - `@ajlbs` introduced a [Custom GPT](https://chat.openai.com/g/g-O3z5GmDPL-bhagvad-gita-answer-to-all-your-questions) that provides insights inspired by the Bhagavad Gita.
    - `@perfectpixels` presented an idea that uses program monitoring chat to decide which custom GPTs the message should go to, `@rjkmelb` suggested this relates to **Mixture of Expert (MoE)** and provided a [link](https://chat.openai.com/share/4f2231d7-05f6-4a8c-9597-66dad36dd2b0) for more information.
    - `@niyohn.` asked for tools to create an **embeddable chat app featuring a Custom GPT**. `@rjkmelb` suggested no current tools but it can be achieved via building out with Assistants API.
    - `@leoalvarenga` sought advice for providing instructions to GPTs. `@.pythagoras` and `@adx2061` suggested a format mimicking programming languages using colons and brackets for better accuracy.
    - `@8020` reported that their Custom GPT, which extracts text from a file and summarizes it, faced issues with the GPT-4 API, suggesting the issue lies within custom GPTs, not the API itself.


### ‚ñ∑ Channel: [prompt-engineering](https://discord.com/channels/974519864045756446/1046317269069864970) (83 messages): 

- **Prompt Engineering Techniques**: `@madame_architect` shared recently published prompting techniques such as Chain of Note, Contrastive Chain of Thoughts, System 2 Attention, Thread of Thoughts, Take a Deep Breath, Emotional Prompts, Simulation Theory of Mind, and Step Back Prompting. Each technique was supplemented with a corresponding ArXiv reference number for further reading.
- **Experience with GPT-3**: `@exh0rt` discussed their experience of working on a prompt designed like a game with specific rules and outlined challenges in maneuvering GPT's interpretations of the rules, having it maintain a desired tone, and dealing with instructional conflicts.
- **Generating Outcomes**: `@eskcanta` suggested that `@exh0rt` provide clear instructions that detail what the AI is supposed to do rather than stating what it should not do, to avoid confusion and foster better outcome generation.
- **Identifying Conflicts**: `@eskcanta` highlighted the importance of identifying instructional conflicts within the prompts given to the AI. They suggested asking the AI to evaluate instructions for ambiguity, potential conflict, and confusion, and to list points of conflict.
- **Discussion on Tone and Language**: `@exh0rt` and `@eskcanta` had an extensive discussion on setting a tone for the AI, dealing with instructional conflicts concerning language use (jargon vs technical terms), and communicating expectations to the AI effectively. They further detailed processes for conflict resolution, understanding the AI's interpretation of instructions, and setting up efficient communication rules.


### ‚ñ∑ Channel: [api-discussions](https://discord.com/channels/974519864045756446/1046317269069864970) (83 messages): 

- **API-disucssions on OpenAI Discord Server**: Members `@exh0rt` and `@eskcanta` discuss issues with the former's instructions to a language model. Key suggestions from `@eskcanta` included:
    - Directly telling the AI what to do instead of using negative language (i.e., what not to do).
    - Identifying conflicting instructions and rectifying them to avoid confusion.
    - Clearly defining contexts and expectations.
    - Avoiding repetition as the AI has a good memory and can comprehend from the first instance.
    - Making sure the instructions don't have unnecessary aggression as the AI is programmed to be compliant and not argue.
- `@exh0rt` contemplated incorporating GPT's suggestions for clarification and resolving conflicts within his script-generating game prompt setup. He planned to run the modified game and see if the newer set of rules were easier for the AI to handle.
- Later, `@madame_architect` shared new techniques for prompt engineering identified in various research papers published in the last 30 days. Some ideas included "Chain of Note", "Contrastive Chain of Thoughts", "System 2 Attention", "Thread of Thoughts", "Take a Deep Breath", "Emotional Prompts", "Simulation Theory of Mind", and "Step Back Prompting".
- `@leoalvarenga` was seeking a template for creating custom GPT setups, but no responses were given to his query within the captured discussion.
- `@exh0rt` summarized his understanding and main takeaways from the detailed discussions into a succinct list of rules for future reference, which `@eskcanta` further clarified.


        

---

## [LangChain AI](https://discord.com/channels/1038097195422978059) Discord Summary

- Extensive exploration into **LangChain's capabilities**, with members discussing intricate functionality, like setting similarity threshold within RAG Retriever to prevent hallucination, implementing interleaved streaming in React and ascertaining specific file locations in LangChain documentation.
- **Streaming responses to FastAPI endpoints** was a topic brought up as a direct query concerning OPENAI_FUNCTIONS_AGENT and AsyncCallbackHandler function.
- A bounty was offered for the **integration of LangChain into E2B**, an open-source sandbox for AI agents with [details found on GitHub](https://github.com/e2b-dev/E2B/issues/242).
- **Debugging Python code in VS Code** whilst using LangServe was addressed, with successful application of the "Debug currently file and add path" configuration and further alternative debugging approach suggestions.
- The discovery that `qaTemplate` is now **deprecated in JavaScript** led to the suggestion of the usage of **QChainoption{}** instead.
- Several helpful resources and potential collaborative opportunities were shared like the [`analyticsvidhya.com` article](https://www.analyticsvidhya.com/blog/2023/11/model-quantization-for-large-scale-deployment/) on model quantization for large-scale deployment, and the invitation for contributions in the [novelspace.tech project](novelspace.tech).
- Unresolved requests for guidance, including a **LangChain JavaScript starter boilerplate** and assistance in implementing streaming with **langchain + GPTCache**.
- Member `@jasonzhou1993` showcased a [YouTube video](https://youtu.be/AVInhYBUnKs?si=qKD0Qaz7DONhsRV2) of a project where they created a research agent with autogen and sought community feedback.

**LangChain AI Channel Summaries**

### ‚ñ∑ Channel: [general](https://discord.com/channels/1038097195422978059/1038097196224086148) (18 messages): 

- **Interleaved Streaming in React Framework**: `@liminalstvte` asked about implementing interleaved streaming in the React framework, specifically he wants to detect when a function in Langchain LLM is called and then provide an answer and continue the conversation.
- **Location of Documented Files in LangChain**: Users `@daii3696` and `@baytaew` sought guidance on how to find the exact file locations that are frequently referenced in LangChain documentation, such as 'Defined in docs/api_refs/langchain/src/chains/conversational_retrieval_chain.ts:33'.
- **Streaming Responses to FastAPI Endpoints**: `@sid.pocketmail` requested assistance in streaming responses to a FastAPI endpoint for OPENAI_FUNCTIONS_AGENT, asking for specifics on the AsyncCallbackHandler function.
- **Preventing Hallucination in RAG Retriever**: `@legendary_pony_33278` inquired about setting a similarity threshold for the RAG Retriever (Faiss or Chroma) such that if no document in the vector database exceeds the threshold, no source is returned. This, they believe, would help prevent hallucination.
- **Bounty for LangChain Integration into E2B**: A financial reward was offered by `@unicorn1997` for integrating LangChain into E2B, an open-source sandbox for AI agents. They provided a [link](https://github.com/e2b-dev/E2B/issues/242) to the bounty details on GitHub.


### ‚ñ∑ Channel: [langserve](https://discord.com/channels/1038097195422978059/1170024642245832774) (3 messages): 

- **Debugging Python code in VS Code while using langserve**: `@virtualmasterpieces` initially struggled with setting up debugging for his Python code in VS Code while using LangServe. His initial attempt using a specific configuration in `launch.json` didn't yield the desired result.
- **Found Solution for Debugging**: Later, `@virtualmasterpieces` found a solution to his debugging issue by using the "Debug currently file and add path" configuration.
- **Alternative Debugging Approach**: `@veryboldbagel` suggested an alternative approach to debugging, advising to first try debugging the chain itself instead of debugging the chain through the server. This tactic could also be useful for writing unit tests/integration tests for the chain exposed by the server.


### ‚ñ∑ Channel: [langchain-templates](https://discord.com/channels/1038097195422978059/1170025009960456282) (5 messages): 

- **Setting Input Keys in the Prompt**: User `@liminalstvte` advised to set input keys in the prompt.
- **QA Template Deprecation in JS**: User `@menny9762` discovered that the `qaTemplate` is now deprecated in JavaScript, suggesting that this could be why the prompt was ignored. He stated adapting his usage to **QChainoption{}**.


### ‚ñ∑ Channel: [share-your-work](https://discord.com/channels/1038097195422978059/1038097372695236729) (3 messages): 

- **Model Quantization for Large-Scale Deployment**: `@soumyadarshani` shared an article on [analyticsvidhya.com](https://www.analyticsvidhya.com/blog/2023/11/model-quantization-for-large-scale-deployment/) discussing model quantization intended for large-scale deployment.

- **The Next Frontier of Email Efficiency with LLMS**: `@soumyadarshani` also introduced an article on [The Next Frontier of Email Efficiency with LLMS](https://www.analyticsvidhya.com/blog/2023/11/the-next-frontier-of-email-efficiency-with-llms/).

- **Novelspace Project Collaboration**: `@benji8214` is seeking collaboration in building out infrastructure at [novelspace.tech](novelspace.tech) and [elysium.novelspace.tech](elysium.novelspace.tech), web apps using Langchain for chatbots. The project focuses on creating images for each chat response using the LCM SDXL model on Replicate.

- **AI Smart Career Start**: `@shving90` posted a link to [AI Smart Career](https://www.smartcareer.ai/early-access/get-started), a platform dedicated to helping users define a career path in AI.


### ‚ñ∑ Channel: [tutorials](https://discord.com/channels/1038097195422978059/1077843317657706538) (3 messages): 

- **Langchain JavaScript Starter Boilerplate**: User `@Faizul Ahemed` requested if anyone has a **langchain JavaScript starter boilerplate repository**.
- **Streaming Implementation with Langchian + GPTCache**: `@sako_70104` expressed need for help on how to implement **streaming** with **langchian + GPTCache** as they were unable to find any relevant information.
- **Research Agent with Autogen**: `@jasonzhou1993` shared a [YouTube link](https://youtu.be/AVInhYBUnKs?si=qKD0Qaz7DONhsRV2) to a project where they created a **research agent with autogen**, where they verify each other's work, and asked for feedback from the community.


        

---

## [Nous Research AI](https://discord.com/channels/1053877538025386074) Discord Summary

- Discussion regarding a new concept coined as **"knowledge-guided attention"** for AI models introduced by `@maxwellandrews`, aiming at efficient handling of long documents by creating a temporary entity graph. This approach is designed to resemble human recall processes by focusing on entity relationships rather than verbatim text. A GitHub repository for relevant research on a [knowledge graph attention network](https://github.com/xiangwang1223/knowledge_graph_attention_network) was shared.
- Conversations about AI/ML career paths, with `@jaisel` asking about how others knew they wanted to focus on ML/AI. `@teknium` shared his personal experience that was sparked with the advent of stable diffusion and the release of chatgpt. Also, during this discussion, two YouTube videos were posted, however, no discussion around these videos took place.
- Detailed metric scores of the [Qwen/Qwen-72B model](https://github.com/Nous-Research/hf-causal-experimental) were shared in the benchmarks log. An issue was raised concerning a potential problem with the `bigbench` task by main.ai, while `@gabriel_syme` engaged the group to explain the meaning behind the benchmarking data.
- Sharing of posts highlighting new techniques, including one that enables a **70b LLM inference on a single 4GB GPU**, and another introducing **Adept Experiments** as a possible technique for fine-tuning agents. The size of **StableLM** was discussed with **HuggingFace listing it as 2.8B**. Various links were shared without context.
- Discussions on various language models, including **1.8B Qwen**, **72B Qwen**,  and **70B LLaMA-2**. Models were compared considering the performance and mentioned a need for independent evaluations. Community interest was expressed in **Open Source Contributions**, and multilingual data was discussed. The potential for future models like **Hermes 2.6**, **Qwen 3b**, **Qwen 14b**, **Yi 34B**, a 70B model, **Mistral 70b** or **Yi 100b** were also a point of discussion.
- A pizza emoji (üçï) was shared in the welcoming channel by user `@rgbkrk` without any provided context.
- Discussion on the best stack for pretraining, conversations around hardware requirements for GGUF models, and instability of Quant models with function calling. User `@b_mc2` posted a link and asked for details about vision Hermes. Discussion on SERP API pricing and alternatives took place.
- Queries about the **Collective Cognition Models on Huggingface Leaderboard** and clarification on project ownership concerning **Open Access AI Collective**.
- A comic relief message mentioning **LIGHT MODE**, a common display option in applications, was shared suggesting an ongoing discussion or inside joke within the community about preferred display modes.

**Nous Research AI Channel Summaries**

### ‚ñ∑ Channel: [ctx-length-research](https://discord.com/channels/1053877538025386074/1108104624482812015) (1 messages): 

- **Knowledge-guided Attention**: `@maxwellandrews` proposed a concept of focusing the attention of AI models more efficiently when dealing with long documents. His concept, termed "knowledge-guided attention," involves creating a temporal entity graph in a "scratchpad" while sliding over the context with a fixed-sized window (e.g., 2048 tokens). The model would then attend between the user's query and the knowledge graph and potentially the original passages that were used to create the relevant nodes in the knowledge graph. He emphasized that this approach is more reflective of how the human mind works - instead of recalling verbatim text, we remember a compressed representation of entity relationships (essentially an entity embedding). He shared a potentially relevant GitHub repository of a [knowledge graph attention network](https://github.com/xiangwang1223/knowledge_graph_attention_network).


### ‚ñ∑ Channel: [off-topic](https://discord.com/channels/1053877538025386074/1109649177689980928) (7 messages): 

- **AI/ML Career Choices**: User `@jaisel` instigated a discussion about career paths in AI/ML, asking how others knew they wanted to dedicate their time to Machine Learning (ML)/Artificial Intelligence (AI)‚Äîand how they found their work focus. `@teknium` shared his personal experience, stating that he became obsessed with AI since stable diffusion and the release of chatgpt.
- **Shared Videos**: Two YouTube videos were shared during the discussion. `@pradeep1148` shared a [YouTube video](https://www.youtube.com/watch?v=FmB6QBVvL-Q). Later, `@jaisel` shared another [YouTube video](https://www.youtube.com/watch?v=uEl2KUZ3JWA&t=1329s), stating it made him reflective after listening to Sam. The topics of these videos were not discussed in the conversation.


### ‚ñ∑ Channel: [benchmarks-log](https://discord.com/channels/1053877538025386074/1131747216244092928) (4 messages): 

- **Benchmark Results for Qwen/Qwen-72B model**: main.ai shared detailed metric scores of [Qwen/Qwen-72B model](https://github.com/Nous-Research/hf-causal-experimental) on tasks such as `truthfulqa_mc`, `arc_challenge`, `arc_easy`, `boolq`, `hellaswag`, `openbookqa`, `piqa`, `winogrande`, `agieval_aqua_rat`, `agieval_logiqa_en`, `agieval_lsat_ar`, `agieval_lsat_lr`, `agieval_lsat_rc`, `agieval_sat_en`, `agieval_sat_en_without_passage`and `agieval_sat_math`. Both the accuracy (`acc`) and normalized accuracy (`acc_norm`) were reported for every given task.
- **Potential Issue with BigBench Task**: main.ai mentioned that there may be a problem with the `bigbench` task due to a EOS/EOD issue.
- **Question about Benchmarks**: `@gabriel_syme` asked for explanations of what the benchmark data means.


### ‚ñ∑ Channel: [interesting-links](https://discord.com/channels/1053877538025386074/1132352574750728192) (16 messages): 

- **Performance of New_Models**:`@metaldragon01` shared [a blog](https://medium.com/@lyo.gavin/unbelievable-run-70b-llm-inference-on-a-single-4gb-gpu-with-this-new-technique-93e2057c7eeb) regarding a new technique that enables a **70b LLM inference on a single 4GB GPU**. In a later discussion, `@euclaise` and `@teknium` had a discussion about the impressive results of a **1.8B GSM8K model**, although some suspicions were raised.
- **Agent Fine-tuning**: `@metaldragon01` queried whether there should be more focus on fine-tuning agents after sharing [a blog](https://www.adept.ai/blog/experiments) introducing **Adept Experiments**.
- **Introduction of Adept Experiments**: `@coffeebean6887` announced the introduction of **Adept Experiments** which might be related to fine-tuning agents.
- **Mistral and Bugatti Collaboration**:`@atgctg` shared a [video](https://www.youtube.com/watch?v=0S2NbZQgD7w) about an interesting partnership between **Mistral and Bugatti**.
- **Model Comparisons**: `@teknium` raised a question about the size of **stableLM**. In response, `@euclaise` clarified that **Hugging Face lists it as 2.8B**.
- **Shared Links**: Various links were shared by the users:
    - [vxtwitter.com](https://vxtwitter.com/justinetunney/status/1729940628098969799?s=46&t=stOPrwZiN_fxSK0RuC8Flg) by `@tsunemoto`.
    - [fxtwitter.com](https://fxtwitter.com/E0M/status/1730271657129025867) by `@sanketpatrikar`.
    - [twitter.com](https://twitter.com/huybery/status/1730174493841358925) by `@nods`.
    - [Google Docs link](https://docs.google.com/document/d/1tza0OIdTZNNjTqhkWZLRC9ha9Sp7lumGF5ytthx_Ozw/edit) by `@atgctg`.
    - [Hugging Face models](https://huggingface.co/Qwen/Qwen-72B) and [Hugging Face models](https://huggingface.co/Qwen/Qwen-1_8B) by `@euclaise`.
    -


### ‚ñ∑ Channel: [general](https://discord.com/channels/1053877538025386074/1149866623109439599) (240 messagesüî•): 

- **New Models & Evaluation**: Users discussed various language models, including **1.8B Qwen**, **72B Qwen**, and **70B LLaMA-2**. Comparisons were made between these models and **Mistral**, **StableLM**, **GPT-3.5**, and **GPT-4**. Qwen models reportedly outperformed the baselines on various tasks, but independent evaluations were deemed necessary to gain a comprehensive understanding of their performance ([`@teknium`](https://discord.com/channels/1053877538025386074/1131747216244092928/1179713969653551124), [`@teknium`](https://discord.com/channels/1053877538025386074/1131747216244092928/1179779324810744064)).
- **WeAreOnlyHuman Community Livestreams**:
    - [`@altryne`](https://twitter.com/altryne/status/1729626838853402770) announced a series of livestreams to learn how to use platforms such as **WandB** for models and open-source Language Learning Models (LLMs).
- **Open Source Contributions**: User [`@xyzyrz`](https://twitter.com/Teknium1/status/1704346187137188151) showed interest in contributing to open-source ML efforts and sought advice for beginners looking to become involved.
- **Models and Datasets for Non-English Languages**: User [`@zhil_arf`](https://discord.com/channels/1053877538025386074/1112796535638462544/1179647128467288065) suggested translating pre-existing datasets to non-English languages to produce multilingual LLMs.
- **Potential Future Model Updates**:
    - ML model makers discussed strategies for creating future versions of Hermes, such as **Hermes 2.6**, with training possibly planned over models like **Qwen 3b**, **Qwen 14b**, **Yi 34B**, and a 70B model ([`@teknium`](https://discord.com/channels/1053877538025386074/1131747216244092928/1179697757316538370)).
    - Talks about future models like a potential **Mistral 70b** or **Yi 100b** were also mentioned ([`@metaldragon01`](https://discord.com/channels/1053877538025386074/1131747216244092928/1179573203955118081)).
- **Training for Diverse Task**: User `@mihai4256` mentioned the fascinating possibilities of using an audio language model to fine-tune for various tasks.


### ‚ñ∑ Channel: [welcomes](https://discord.com/channels/1053877538025386074/1151415076033658931) (1 messages): 

- Participant `@rgbkrk` offered a pizza emoji (üçï) in the discussion. However, the context or purpose of this contribution is not clear from the provided message.


### ‚ñ∑ Channel: [ask-about-llms](https://discord.com/channels/1053877538025386074/1154120232051408927) (36 messages): 

- **Discussion on best stack for pretraining**: User `@mtybadger` inquired about the best stack for pretraining, expressing dissatisfaction with the mosaicml composer/streaming dataset. 
- **Information about Vision Hermes**: User `@b_mc2` posted a link about a multimodal vision Hermes and asked for notable details such as image size for training, prompt format etc. [[link](https://x.com/Teknium1/status/1726616664668770539)].
- **Discussion on SERP API pricing and alternatives**: Users `@teknium` and `@markopolojarvi` had a discussion concerning the high cost of the SERP API and the potential alternatives, including building their own SERP scraping infrastructures and utilizing Google Custom Search Engine (CSE) or serper API.
- **Hardware requirements for running GGUF models**: User `@umarigan` made inquiries about the hardware needed to run GGUF models swiftly. Subsequent discussions with other users revealed that they were attempting to run these models without a GPU, and were also using different bit versions (q5_k_m and q2_k). 
- **Instability of Quant Models with Function Calling**: User `@raddka` noted that quant models, even at Q6/Q8 versions, are unstable at executing system instructions for function calling when compared to original models like OpenHermes-2.5.


### ‚ñ∑ Channel: [collective-cognition](https://discord.com/channels/1053877538025386074/1154961277748256831) (5 messages): 

- **Collective Cognition Models on Huggingface Leaderboard**: User `@yobibyte` inquired about a collective cognition model that seemingly disappeared from the Huggingface leaderboard. `@teknium` clarified that the model was not deleted and provided the [link to the model on Huggingface](https://huggingface.co/teknium/CollectiveCognition-v1.1-Mistral-7B).
- **Project Ownership Clarification**: Upon further clarification, `@yobibyte` mentioned the *Open Access AI Collective* project associated with the Jackalope model. `@teknium` directed this to `<@257999024458563585>`, stating that these were their projects.


### ‚ñ∑ Channel: [memes](https://discord.com/channels/1053877538025386074/1166105758635655270) (1 messages): 

- User `@nruaif` shared a comic relief message, referencing the **LIGHT MODE** function, typically a display setting in applications. This may suggest an ongoing discussion or inside joke within the community about preferred **display modes**. No further context or follow-up discussion was provided.


        

---

## [Alignment Lab AI](https://discord.com/channels/1087862276448595968) Discord Summary

- Deep learning application in materials discovery: `@entropi` shared a [DeepMind article](https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/) detailing how AI has been used to discover millions of new materials.
- Invite to a **WandB live stream**: `@altryne` invited users to a live stream discussing how to use **WandB** and encouraged those using WandB to connect for future collaborative opportunities. The [stream link](https://twitter.com/altryne/status/1729626838853402770) was provided.
- Questions regarding **Synthia 1.3's** generation: `@imonenext` inquired whether **Synthia 1.3** was the output of **GPT4** and sought clarification about the 'system' and 'instruction' fields in its [HuggingFace dataset page](https://huggingface.co/datasets/migtissera/Synthia-v1.3).
- Inquiry about the **Alignment Labs launch**: `@zolandinho` asked about the expected launch date for **Alignment Labs**.
- The user `@puffy310` indicated intent to investigate an unspecified issue or topic.
- Work and skills overview: `@frankyan.ai` detailed professional experience and skills in full-stack development, software engineering, DevOps practices, and AI project integrations, citing specific experience with ChatGPT.
- Upcoming plans and author of Synthia: `@giftedgummybee` and `@imonenext` discussed upcoming work on system prompts. `@imonenext` and `@nanobitz` conversed about the author of Synthia, with `@nanobitz` providing the author's name (Miggel Tissera) and a [link to his Discord profile](https://discordapp.com/channels/1104757954588196865/1104757955204743201/1174595468592951377).

**Alignment Lab AI Channel Summaries**

### ‚ñ∑ Channel: [looking-for-collabs](https://discord.com/channels/1087862276448595968/1095393077415383261) (1 messages): 

As the task requirement, this prompt is designed to test how an assistant can follow the instruction to summarize a chatbot message history by applying a specific format that matches the given instruction. But it appears to be a misunderstanding as no history messages are provided here, and thus the assistant can't provide a meaningful response. It suggests reviewing the task setup or providing a proper dataset for the assistants to generate the expected output.


### ‚ñ∑ Channel: [general-chat](https://discord.com/channels/1087862276448595968/1095458248712265841) (7 messages): 

- **DeepMind's Discovery of Millions of New Materials**: `@entropi` shared an [article](https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/) from DeepMind, detailing how deep learning has been used to discover millions of new materials.
- **Live Stream on Using WandB with LDJ**: `@altryne` extended an invitation to join a live stream with `LDJ` where they will be discussing how to use **WandB**. The event can be accessed via [this twitter post](https://twitter.com/altryne/status/1729626838853402770) and Altryne also encouraged others who use WandB to reach out for future learning experiences.
- **Query about Synthia 1.3's Generation**: `@imonenext` asked whether **Synthia 1.3** was generated by **GPT4** and provided a link to its [huggingface dataset](https://huggingface.co/datasets/migtissera/Synthia-v1.3). The user also inquired if the 'system' field is the system prompt to GPT4 and the 'instruction' as the user's message.
- **Alignment Labs Launch Inquiry**: `@zolandinho` inquired about the launch date for **Alignment Labs**. The user also sought the assistance of admins to answer their questions.


### ‚ñ∑ Channel: [oo](https://discord.com/channels/1087862276448595968/1118217717984530553) (1 messages): 

- `@puffy310` indicated they **will look into** a particular issue or topic, though the specific topic or issue was not mentioned within the provided context.


### ‚ñ∑ Channel: [looking-for-work](https://discord.com/channels/1087862276448595968/1142242683339944027) (1 messages): 

- **Work Experience and Skills**: User `@frankyan.ai` brings more than 25 years of full stack development and software engineering experience, with a focus on financial sector projects. His skillset includes creating websites and single page applications, designing and implementing microservices, using open-source components and automation tools, and building CI/CD pipelines.

- **DevOps Experience**: `@frankyan.ai` practices DevOps skills, working with Terraform and Ansible scripts to manage cloud resources and set up CI/CD pipelines, logging, monitoring, and tracing infrastructures. 

- **AI Projects**: `@frankyan.ai` has worked with ChatGPT and integrated it into various projects. These include an AI-enhanced resume matching system, making ChatGPT accessible to friends in China, and researching FastChat to support LangChain integration.


### ‚ñ∑ Channel: [oo2](https://discord.com/channels/1087862276448595968/1176548760814375022) (9 messages): 

- **Upcoming Plans**: `@giftedgummybee` asked about any upcoming plans. `@imonenext` replied that they are **working on system prompts**.
- **Synthia's Author**: `@imonenext` inquired about the author of Synthia. `@nanobitz` provided the author's name as Miggel Tissera and shared that they had seen him on Axolotl discord. When `@imonenext` couldn't find him on OpenAccess AI Collective, `@nanobitz` provided a [direct Discord link](https://discordapp.com/channels/1104757954588196865/1104757955204743201/1174595468592951377) to his profile.


        

---

## [Skunkworks AI](https://discord.com/channels/1131084849432768614) Discord Summary

Only 1 channel had activity, so no need to summarize...

**Skunkworks AI Channel Summaries**

### ‚ñ∑ Channel: [off-topic](https://discord.com/channels/1131084849432768614/1140423597454807179) (1 messages): 

- `@pradeep1148` shared a [YouTube link](https://www.youtube.com/watch?v=FmB6QBVvL-Q). The content of the video was not discussed.
        

---

## [LLM Perf Enthusiasts AI](https://discord.com/channels/1168579740391710851) Discord Summary

- **OpenAI Leadership Update**: User `@joshcho_` informed about Sam Altman returning as CEO of OpenAI and the formation of a new initial board as posted on [OpenAI‚Äôs blog](https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board).
- Discussion on **Performance Issues**: Users reported slowness with **Azure OpenAI calls** and slower than usual operation speeds on both unnamed main platform and Azure. On contrast, user `@jet0266_71389` highlighted that **Neuralmagic** tends to demonstrate good CPU performance.
- **Open Source Models and Deployment**: Conversation on potential performance impact of larger context window, with the concern raised by `@thebaghdaddy` about the possible reduction in performance when using larger context window upto **GPT-4**. The community also discussed plans to test the **Starling-lm-7b** model and `@thisisnotawill` expressed the idea of creating a Hugging Face endpoint. User `@robotums` queried about the exposure of log-probabilities in pplx-API to examine perplexities in cross-encoder models. `@thisisnotawill` also looked for advice on running open source models locally and deploying them to Azure, stating a rate of $200/hr for guidance. A helpful resource was shared by `@pantsforbirds`, pointing towards [Mozilla-Ocho‚Äôs Llamafile](https://github.com/Mozilla-Ocho/llamafile) as a potential guide.
- **Event and Project Notification**: `@res6969` announced investor interest for an event in New York City and briefly shared plans to create a **Luma** either in the current day or the next.
- **Appreciation for New Channel Creation**: User `@joshcho_` acknowledged `<@757392677280022549>` for creating the new prompting channel.

**LLM Perf Enthusiasts AI Channel Summaries**

### ‚ñ∑ Channel: [general](https://discord.com/channels/1168579740391710851/1168579740391710855) (1 messages): 

- **OpenAI's New CEO and Initial Board**: User `@joshcho_` shared a [link](https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board) to **OpenAI's blog post** announcing that Sam Altman is returning as CEO and unveiling the company's new initial board.


### ‚ñ∑ Channel: [gpt4](https://discord.com/channels/1168579740391710851/1168582188950896641) (1 messages): 

- **Azzure OpenAI Calls Performance Issues**: `@psychickoala` reported experiencing **slowness with Azzure OpenAI calls**.


### ‚ñ∑ Channel: [opensource](https://discord.com/channels/1168579740391710851/1168606773595349082) (17 messages): 

- **Performance Impact of Large Context Window**: `@dongdong0755` suggested prompting an entire dataset, but `@thebaghdaddy` cautioned that a larger context window often decreases performance, a phenomenon observed till **GPT4**.

- **Testing Starling-lm-7b**: `@thisisnotawill` announced plans to test **Starling-lm-7b** and even create a Hugging Face endpoint. 

- **Query About log-probs Exposure in pplx-API**: `@robotums` asked if the pplx-API exposes log probabilities for examination of perplexities in cross-encoder models.

- **Request for Guidance with Open Source Models**: `@thisisnotawill` requested assistance **with running open source models locally and deploying them to Azure**, offering $200/hr for 1-2 hours of guidance. 

- **Potential Useful Resource Shared**: `@pantsforbirds` shared a potentially useful resource, the Llamafile by [Mozilla-Ocho](https://github.com/Mozilla-Ocho/llamafile), hoping it could be of some help.


### ‚ñ∑ Channel: [speed](https://discord.com/channels/1168579740391710851/1168986766607384638) (1 messages): 

- **Neuralmagic's CPU Performance**: `@jet0266_71389` indicated that **Neuralmagic** seems to have a good CPU performance.


### ‚ñ∑ Channel: [irl](https://discord.com/channels/1168579740391710851/1171569983688560732) (2 messages): 

- **Upcoming NYC Event**: User `@res6969` mentioned that they have **investors interested** in attending an upcoming event in NYC.
- **Creating a Luma**: `@res6969` also mentioned planning to create a **Luma** either today or the next day.


### ‚ñ∑ Channel: [openai](https://discord.com/channels/1168579740391710851/1171903046612160632) (3 messages): 

- **Performance Issues**: Users `@kev.o` and `.psychicKoala` reported experiencing **slower than usual operation speeds**, both on the unspecified main platform and on Azure.


### ‚ñ∑ Channel: [prompting](https://discord.com/channels/1168579740391710851/1179271229593624677) (1 messages): 

- `@joshcho_` expressed gratitude for the creation of the channel, specifically thanking `<@757392677280022549>`.


        

---
The MLOps @Chipro Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

---
The Ontocord (MDEL discord) Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

---

## [AI Engineer Foundation](https://discord.com/channels/1144960932196401252) Discord Summary

Only 1 channel had activity, so no need to summarize...

**AI Engineer Foundation Channel Summaries**

### ‚ñ∑ Channel: [general](https://discord.com/channels/1144960932196401252/1144960932657758210) (4 messages): 

- **AWS re:Invent Sessions**: User `@juanreds` initiated a discussion about the AWS re:Invent sessions.
- **Challenges with AI Adoption**: `@juanreds` expressed concerns on how organizations can start using AI, including decisions around AI applications and processes.
- **Framework of AI Best Practices**: `@juanreds` proposed the idea for an AI Engineer Foundation to create a **standard**, a **framework of best practices**, to guide organizations wanting to adopt AI.
        

---
The Perplexity AI Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

---
The YAIG (a16z Infra) Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.