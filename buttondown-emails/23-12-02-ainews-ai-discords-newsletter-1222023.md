---
id: 23da1a17-7e5f-4c98-b861-a865887fbd6e
title: '[AINews] AI Discords Newsletter  12/2/2023'
date: '2023-12-03T05:35:04.855294Z'
status: sent
type: public
source: api
metadata: {}
original_slug: ainews-ai-discords-newsletter-1222023
---

<!-- buttondown-editor-mode: plaintext -->[TOC] 


## [OpenAI](https://discord.com/channels/974519864045756446) Discord Summary

- **ChatGPT Performance and User Experience**: Concerns were raised about recent perceived changes in GPT performance and interaction, such as "dumbed down" responses, simplification, and lagging. Some users noted difficulty in accessing features on the site — particularly Codex, the tool for generating Python code, which is discontinued. Billing plan cancellation and reactivation issues were reported while efforts to access plugins were met with challenges.
- **ChatGPT Behavior and Customization**: There were discussions on the current behavior of GPT, including its ability to understand and use markdown, as well as the potential of creating 'dynamic hotkeys' and customizing GPT to suit specific user needs. Users also delved into the issue of limiting GPT response length, despite instances where instructions to limit responses might be overlooked by the model.   
- **Conceptual Debates**: Lively conversations took place on comparing AI language use to human concepts. This involved examining the differences between AI and human language comprehension, and the philosophical implications of AI mimicking human initiatives and emotions.
- **Prompting Strategies and Performance**: Users shared their experiences and strategies in refining prompts for improved AI output. Approaches were likened to refining a recipe, with iterative tweaking and assessing of results. Strategies to efficiently use tokens to manage costs, including a shared [token counting tool](https://platform.openai.com/tokenizer), were discussed.
- **Potential Legal Implications**: The legal implications of AI's interaction with copyrighted material was a topic of discussion, arguing whether AI's use of copyrighted materials constitutes infringement or not.
- **Hyper Light Travel and AI**: An in-depth discussion was held suggesting the necessity of AI in hyper light travel, including the potential to navigate and manage energy systems for high-speed movement and the need to transcend the limits of current computing technology. Also, possible challenges in computational hardware within the field of Material Engineering were mentioned.
- **Collaboration and Community Interaction**: There was a shared interest around community collaboration on shared prompts and problem-solving; GitHub and Notion were suggested for sharing and storing prompts, templates, and small files. There was also an indication of an emphasis on respectful guild conduct, with reminders about potential consequences for violating rules.
- **Usage Policy**: It was clarified that unsolicited mass emails are considered as spam under OpenAI rules, even if sent with noble intentions such as reaching out to potential clients.


**OpenAI Channel Summaries**

### ▷ #[ai-discussions](https://discord.com/channels/974519864045756446/998381918976479273) (142 messages): 
        
- **Comparing AI Language to Newton's Conception of 'Body'**: `@posina.venkata.rayudu` opened a discussion comparing AI's use of language to Newton's concept of a 'body'. `@bambooshoots` elaborates on how philosophers like Wittgenstein and Chomsky's views on language contrast this analogy, emphasizing human language's intricate tie with human forms of life, activities, and culture. They further discuss how AI's proficiency in replicating language syntax does not equate to human language understanding. Despite GPT-4’s ability to mimic human-like language usage, it still lacks the consciousness, intentionality, and intrinsic understanding of language that humans possess.
- **Lag in chat.openai.com**: Users `@muntderi.q` and `@xyza1594` reported experiencing lag on ChatGPT's website. The reason for the lag is not specified.
- **Accessing Codex**: `@kosa001` asked for help accessing Codex AI, an AI that can generate python code. `@.dooz` responded that Codex had been discontinued by OpenAI as of 2023.03.23 and recommended GPT-4 as a replacement.
- **Troubles with GPT-4**: User `@123431s` voiced frustration with GPT-4’s performance, noting that it seemed less capable than previous weeks. The user also mentioned a lag issue with ChatGPT's page.
- **Discussion on AI and Consciousness**: Many users, led by `@bambooshoots` and `@.dooz`, explored whether an AI can truly mimic human emotions, intentions, and consciousness, or whether these aspects of human communication can just be considered complex forms of information. The discussion posed philosophical questions about the nature of consciousness in AI and whether perfect mimicry can be distinguished from genuine understanding.
- **AI in Hyper Light Travel**: `@mysticmarks1` and `@quanta1933` had an in-depth discussion about the necessity of AI in hyper light travel and the need to transcend limits of current computing technology. They discuss the concept of creating an AI program capable of navigating and managing energy systems for high-speed movement, underscoring the importance of AI in these fields. They also delve into the challenges and considerations in the field of Material Engineering, specifically in the context of computational hardware.


### ▷ #[openai-chatter](https://discord.com/channels/974519864045756446/977697652147892304) (196 messages🔥): 
        
- **ChatGPT API Scalling and Performance Issues**: Multiple users, including `@null_of_gehenna` and `@sirpoggy` discussed about the lagging, unresponsiveness, and connection errors they have been experiencing with OpenAI's GPT. `@null_of_gehenna` speculated that OpenAI might be experiencing scaling issues, reaching a server capacity near 90%, while `@sirpoggy` mentioned that trying various browsers, VPN settings, and devices resulted in his service working again. 
- **Concerns about ChatGPT's Behavior**: Users discuss about perceived changes in the behavior of ChatGPT. `@dannypia_85631` expressed disappointment, stating that the AI has been "dumbed down" while others felt the responses were too simplified. Others users such as `@themandalorian` and `@lk_jinxed` claimed their experience was satisfactory. 
- **Customizing GPT**: Users `@onebyte` and `@fettywhap` showed interest in customizing GPT's and queried about the possibility of using GPT builder for creating action schema and tailoring AI for specific uses in daily life. User `@merpnderp` expressed a desire to build a gaming website using GPT. 
- **Other Technical Issues**: `@mrgahan` reported issues with profile images not showing in custom GPTs. `@feedonyourtearskappa` raised a concern about error in generating images using DALL-E. User `@captainstarbuck` reported issues with Custom GPT DNS TXT record Verification. 
- **Usage Policy and Spamming**: User `@localhorse` inquired about how OpenAI determines what counts as spam, in the context of outreach to potential clients. Based on a discussion involving `@lugui` and `@itszeph.`, it was clarified that unsolicited mass emails are considered spam, regardless of intent.


### ▷ #[openai-questions](https://discord.com/channels/974519864045756446/974519864045756454) (57 messages): 
        
- **Billing Plan Cancellation and Reactivation**: User `@simone4` experienced an issue where their billing plan was canceled unexpectedly and was unable to reactivate it. In response, `@satanhashtag` suggested reaching out to `support@openai.com`.
- **Running Multiple ChatGPT Sessions**: User `@exh0rt` asked about the possibility of running two ChatGPT chats at once. `@captainsonic` suggested that switching between chats in the same tab, or potentially opening two different tabs, could be a solution. 
- **Performance Issues and Usage Limits**: A number of users, including `@Shunrai`, `.daekar`, and `@highsquash`, raised concerns about performance issues, lagging and constantly hitting usage limits with certain GPT models.
- **Chat History Loading Errors**: Users `@bloodyfire345`, `@blocky007`, `@aesthetic_person_123`, and `@formatted_poorly` reported that previous chats were not loading. They experienced a unified "Unable to load conversation" error across different browsers. The issue appeared to be resolved later.
- **Tools and Sharing Prompts**: `@gateraidme555` was looking for tools to load gpts with a github repo while `@benjick.` sought recommendations for a platform or app for sharing prompts with function calls for collaborative experimentation.


### ▷ #[gpt-4-discussions](https://discord.com/channels/974519864045756446/1001151820170801244) (55 messages): 
        
- **Dynamic Hotkeys Discussion**: `@amanshrestha` initiated a discussion on creating dynamic hotkeys for GPT. `@exh0rt` shared their previous attempt at this but had given up before they could achieve the result they wanted. They expressed interest in a collaborative attempt with `@amanshrestha`.
   
- **OpenAI Subscription Waitlist Questions**: `@og.griz` asked how the waitlist works for people trying to subscribe, to which `.pythagoras` responded, stating OpenAI tends not to clarify such matters.
  
- **Limitation on GPT Assistant's Answer Length**: `@yuuns.` asked how to limit the length of the answers from a GPT assistant. `@mysticmarks1` suggested giving straightforward instructions for a two-sentence answer, albeit `@yuuns.` noted that GPT sometimes ignores such instructions.
  
- **Token Counting Tool**: `@mysticmarks1` mentioned the presence of a token counting tool available at `[https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)`.
  
- **Accessing Plugins Issue**: `@intermatrixnaut` expressed difficulty in accessing plugins in their custom GPT setup. `@eskcanta` suggested reaching out to OpenAI support for assistance.


### ▷ #[prompt-engineering](https://discord.com/channels/974519864045756446/1046317269069864970) (103 messages): 
        
- **Discussing Prompts and AI Output Improvements**: `@exh0rt` shares their experiences of improving AI output using *megaprompts* – a process compared to refining a recipe. They describe their testing method as running the prompt, checking the output and refining based on results.
- **Challenges in AI Understanding User Intent**: `@exh0rt` mentioned their difficulties in getting the AI to understand their "rift", and highlighted potential issues where subtleties in user text might create loopholes for the AI, leading to not meeting user intent.
- **AI and Copyright Concerns**: `@captainsonic`, `@amanshrestha`, and `@eskcanta` discussed the potential legal implications of AI learning from copyrighted material. `@the_jmc` argued that remembering text doesn't necessarily infringe copyright.
- **AI and Markdown**: Both `@cat.hemlock` and `@og.griz` discussed the AI's proficiency with the markdown language. It was concluded that it understands and uses it remarkably well.
- **Efficient Use of Tokens**: `@yuuns.` asked how to limit AI responses to a certain length. `@cat.hemlock` advised against using the term "tokens" and suggested instructing the AI to provide simpler, more direct answers. They also shared a link to a tool they made to assist in measuring token usage.
- **Sharing and Storing Prompts**: `@cat.hemlock` suggested GitHub as a good platform for storing prompts, templates, and other small files, which could be accessed freely and rolled back to previous versions as needed. `@exh0rt` preferred using Notion, as they found it easier and more convenient to use.


### ▷ #[api-discussions](https://discord.com/channels/974519864045756446/1046317269069864970) (103 messages): 
        
- **Discussions on Prompts and Performance**: Participants including `@perfectpixels` and `@exh0rt` discussed how to evaluate the effectiveness and performance of a prompt with OpenAI's GPT. `@exh0rt` used the analogy of gradually "adding salt" in cooking to describe the iterative, fine-tuning process of crafting a prompt.
- **Costs and Tokens**: `@dt` and `@cat.hemlock` shared insights on optimizing the token usage of GPT to manage cost. `@cat.hemlock` provided a tool called [Platform OpenAI Tokenizer](https://platform.openai.com/tokenizer) to estimate token usage, and discussed how providing detailed context instructions for GPT can lead to less efficient token usage.
- **Markdown Use in Prompts**: `@cat.hemlock` and `@og.griz` discussed the use of markdown language in OpenAI prompts. `@cat.hemlock` provided an online guide on markdown language ([Markdown Guide](https://markdownguide.org)) to assist users in effectively utilizing markdown in their prompts.
- **Intellectual Property**: There was a brief discussion on potential copyright issues regarding the AI's training on copyrighted text. Participants including `@captainsonic` and `@amanshrestha` weighed in on the matter.
- **Prompt Limitations**: A question was raised by `@yuuns` about how to limit the length of GPT assistant responses. The issue of the GPT model not always respecting instruction parameters that limit the length of the output was noted.


        

---

## [Nous Research AI](https://discord.com/channels/1053877538025386074) Discord Summary

- Several discussions took place regarding **advancements in AI models and related technologies**:
  - Graph-based methods were explored for *querying and updating a model* (![source](https://github.com/langchain-ai/langchain/tree/master/templates/neo4j-advanced-rag))
  - Deep discussions on the **performance and training of AI models** like qwen72b, qwen14b, Nous-Hermes 2.5 (![link](https://github.com/QwenLM/Qwen/blob/main/eval/EVALUATION.md)), and a variety of Mistral derived models alongside HuggingFaceH4/mistral-7b-sft-beta.
  - User `@yorth_night` posted two different links <!--[Twitter link](https://vxtwitter.com/ArmenAgha/status/1731076069170835720), [GitHub link](https://github.com/unslothai/unsloth)--> on the interesting-links channel.
  
- **User Experience and GUI Tools**: [Tarsier](https://github.com/reworkd/tarsier) and [vimGPT](https://github.com/ishan0102/vimGPT) GUI tools were spotlighted alongside discussion about voice messages with XTTS2 in OpenKlyde.

- **Hardware Discussions and Recommendations**: Suggestions were made about acquiring used 3090 GPUs and server hardware for AI projects (![source](https://openrouter.ai/docs#models)), and potential issues were flagged.

- **Efficiency of AI Models and Training Strategies**: Enthusiasm was shown for both Nous Hermes 2.5 training and new Vision models for browser navigation tasks. Experimental fine-tuning techniques for large-scale models were suggested (![source](https://twitter.com/oscar_zhiqiu_xu/status/1730691582767370524)), and the effectiveness of the small-sized Airoboros dataset was remarked upon (![source](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-m2.0)).

- **Difficulties with AI Response Models**: Users reported problems with getting a complete response from local Large Language Models (LLMs) (![source](https://pastebin.com/qsbLC333)). OpenHermes-2.5 and deepseek-chat 67B language model responses were provided (![source](https://pastebin.com/R3ZHX54E)).

**Nous Research AI Channel Summaries**

### ▷ #[ctx-length-research](https://discord.com/channels/1053877538025386074/1108104624482812015) (6 messages): 
        
- **Exploring Graph-Based Methods**: `@spaceman777` brought up the possibility of querying and updating a graph using function calling. This would allow for model adjustments without direct modifications. They also suggested implementing a semantic search on the graph. As an example, they shared [this link](https://github.com/langchain-ai/langchain/tree/master/templates/neo4j-advanced-rag) for a hierarchical graph setup that supports relational and analogical thinking (RAG) and could yield interesting training data for constructing integrated knowledge graphs at a deeper level.
- **Thoughts on Entity Extraction and Knowledge Graphs**: `@maxwellandrews` presented the idea of utilizing foundation models for entity extraction and projecting extracted entities into an editable and appendable knowledge graph. They proposed that the optimal result might be achieved via cross-attention between the knowledge graph and the attention system, using ground-truth Relational and Analogical Thinking (RAG) datasets.
- **Considerations for Metadata**: `@maxwellandrews` also stressed the importance of considering diverse dimensions during the extraction process. This includes not only intrinsic dimensions such as the event narrative, but also extrinsic metadata dimensions such as the page number of the event or the document's author and publication date. Successful comprehension of these metadata dimensions is crucial for comprehensive extraction.


### ▷ #[off-topic](https://discord.com/channels/1053877538025386074/1109649177689980928) (9 messages): 
        
- **Running Text Through Local LLM**: `@airpods69` asks for assistance in running a text through a local large language model (LLM). They mention that **GPT-3.5 stops after 23 questions** while **Bard** refuses to answer all questions. The text in question is provided in a [Pastebin link](https://pastebin.com/qsbLC333).
- **Request Clarification**: `@intervitens` asks for clarification about whether all questions need to be asked at once, to which `@airpods69` confirms.
- **OpenHermes-2.5's Response**: `@tsunemoto` provides an unspecified response from OpenHermes-2.5, a language model.
- **Providing OpenHermes-2.5's Answer**: `@intervitens` shares another version of the response from OpenHermes-2.5 and provides it in a [Pastebin link](https://pastebin.com/R3ZHX54E).
- **Response from Deepseek-chat 67B**: For variety, `@tsunemoto` provides a response from deepseek-chat 67B language model (full response not specified).


### ▷ #[interesting-links](https://discord.com/channels/1053877538025386074/1132352574750728192) (3 messages): 
        
- User `@b_mc2` shared a [GitHub link](https://github.com/unslothai/unsloth) to the project "unsloth".
- User `@yorth_night` posted a [Twitter link](https://vxtwitter.com/ArmenAgha/status/1731076069170835720) related to a discussion on the channel.
- User `@yorth_night` posted an emoji reaction (`<:stare:1019075524070481990>`), however, without any context, it's unclear what this reaction pertains to.


### ▷ #[general](https://discord.com/channels/1053877538025386074/1149866623109439599) (283 messages🔥): 
        
- **Qwen Model Performance**: In an in-depth discussion `@arankomatsuzaki` and `@teknium` were trying to understand the underwhelming performance of **qwen72b** compared to **qwen14b** on multiple benchmark tasks based on agieval numbers. Discussion showed skepticism about the effect of leaked Chinese benchmarks on overall scores. `@tokenbender` mentioned that the unavailability of specific **agieval evaluations** on the [Qwen GitHub page](https://github.com/QwenLM/Qwen/blob/main/eval/EVALUATION.md) hamper their ability to further analyize. 
- **Nous Hermes Training**: Users expressed excitement and interest for **Nous Hermes 2.5** training, discussing the potential costs and time requirements involved especially considering models in the range of **70B**. `@teknium` estimated it may take up to 30 days given their current hardware capability (*8x h100s*).
- **Vision Models for Browser Navigation**: `@papr_airplane` asked about the best model for **browser navigation tasks**. `@teknium` announced the impending release of the **Nous-Hermes 2 Vision** model, designed to significantly improve OCR capabilities. Users expressed anticipation about testing the new model.
- **AI Model Finetuning**: `@mihai4256` shared experiences of finetuning a variety of Mistral derived models with smaller datasets using the alpaca finetune, highlighting **HuggingFaceH4/mistral-7b-sft-beta** as the best-performing model. Conversation also gravitated towards some peculiarities around `@n8programs`' **Hermes model**, where it behaved unexpectedly with the **ChatML prompt format** in **LM Studio**.
- **User Interface Tools**: Several tools were shared and discussed: a **browser navigation tool** by reworkd named [Tarsier](https://github.com/reworkd/tarsier), a **Vision models** GUI running tool named [vimGPT](https://github.com/ishan0102/vimGPT), and `@elbios`'s fork of **OpenKlyde** that has voice messages with **XTTS2**, and discussion about the provisional nature of much of the existing overtly engineered software offerings.


### ▷ #[ask-about-llms](https://discord.com/channels/1053877538025386074/1154120232051408927) (42 messages): 
        
- **Discussion on GPU Acquisition and Set Up for AI Projects**: User `@raddka` considers buying used 3090 GPUs and server hardware for an AI project, considering power efficiency and compatibility with GPUs. `@intervitens` provided advice on potential hardware and setup issues and suggests alternative solutions, such as buying more generic motherboard CPU combos.

- **Discussion on Different AI Models and Pricing Strategies**: Users, especially `@fullstack6209`, ponder on various AI models currently in the market, from Nous-Capybara-34B to NeuralHermes-2.5-Mistral-7B and their associated costs. Different AI providers are compared, with a special mention on Gryphe's models and their affordability, along with the [OpenRouter AI documentation](https://openrouter.ai/docs#models) for more details.

- **Discussion on UnSloth and Eleuther's Harness vs OpenAI/Evals**: `@main.ai` and `@manveerxyz` had a discussion on the functionality and speed of UnSloth, and the community's preference for Eleuther's harness over OpenAI/evals for LM training. `_automagic` responded stating trust as a factor.

- **Proposal for Experimental Fine Tuning Techniques**: `@andrewnc` proposed an innovative strategy for optimizing large-scale models like Goliath 34B or 7B using weight selection techniques from Oscar Xu's project shared on [Twitter](https://twitter.com/oscar_zhiqiu_xu/status/1730691582767370524). `_automagic` responded mentioning a similar work done on [Mistral-3.3B](https://huggingface.co/typeof/mistral-3.3B).

- **Discussion on Airoboros Dataset**: `@crainmaker` and `@teknium` engaged in a conversation about the Airoboros dataset, considered to be highly effective despite its small size. The related dataset was referenced at [Huggingface](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-m2.0).


        

---

## [LangChain AI](https://discord.com/channels/1038097195422978059) Discord Summary

- Prolific discussion on the use and challenges of **LangChain Applications**, featuring an active exchange of code queries, reported issues, and pertinent solutions:
    - Shared an OpenML Guide on GitHub for wide-ranging resources related to Machine Learning: ["GitHub link"](https://github.com/severus27/OpenML-Guide).
    - A code implementation issue of LangChain's **LLM** application with Cohere AI related to unexpected comprehensive model response: "*...unexpected comprehensive response from the model instead of simple translation*".
    - Report of issues encountered with LangChain's *UnstructuredExcelLoader* and *UnstructuredWordLoader* in the latest version.
    - A [discussion](https://discord.com/channels/1038097195422978059/1038097196224086148) on the pros and cons of transitioning from LangChain to OpenAI's new assistant API.
    - Inquiry about open source models' deployment for generating embeddings and context addition in LangChain's *SQL Agent*.
- Dialogue on **GPT Models in LangChain**, focusing on enhancing GPT-3's reasoning capability to a level similar to GPT-4, specifically in a SQL context: "*...lack of success despite varying contexts and prompts*".
- A query about tracking token spent and costs during the execution of a chain as a RemoteRunnable in LangChain. Reported difficulty in tracking when running the chain directly.
- Showcase of individual projects in the community:
    - A [character AI chatbot](https://github.com/ossirytk/llama-cpp-chat-memory) developed using LangChain, ChainLit, and Chroma, that supports text, pdf, and json documents including metadata filtering.
    - A [Python lessons series](https://www.youtube.com/playlist?list=PL1eVNGcrHFPfZjsKzGpfW9mJIJaUcyIjN) dedicated to AI application development, starting from basics to more advanced topics, fostering the spirit of collaborative learning.

**LangChain AI Channel Summaries**

### ▷ #[general](https://discord.com/channels/1038097195422978059/1038097196224086148) (37 messages): 
        
- **LangChain Applications and Challenges Discussion**:
    - `@severus_27` shares link to **OpenML Guide** on GitHub [GitHub link](https://github.com/severus27/OpenML-Guide), a resource containing open source books, courses, tutorials etc. related to Machine Learning.
    - `@.bifunctor` shares a code implementation of LangChain's **LLM** application with *Cohere AI* and raises a question about the unexpected comprehensive response from the model instead of simple translation.
    - `@quantumqueenxox` and `@seththunder` discuss issues they've experienced with LangChain's *UnstructuredExcelLoader* and *UnstructuredWordLoader* in the latest version.
    - `@rafacc.eth` questions the community whether it is worth moving from *LangChain to OpenAI*'s new assistant API and `@lhc1921` provides their perspective about sticking with LangChain.
    - `@firefistape` queries about using open-source models for generating embeddings in LangChain and adding context to the database for LangChain's *SQL Agent*.
    - Several issues and code-specific queries related to LangChain are being discussed by `@lhc1921`, `@quantumqueenxox`, `@seththunder` and `@firefistape`.

- **Advanced Usage of GPT Models in LangChain**:
    - `@plakis` asks if anyone has managed to improve *GPT-3's reasoning capability* to a level similar to GPT-4, particularly for SQL. Notes their lack of success despite varying contexts and prompts, and wonders if a fine-tuned model may help.


### ▷ #[langserve](https://discord.com/channels/1038097195422978059/1170024642245832774) (1 messages): 
        
mbaburic_24680: Thx, <@1033432389516546158> . I tried setting "include_callback_events=True" but to no avail. I simply wasn't able to programmatically track the token spend with "get_openai_callback()" when running the chain as a RemoteRunnable. When running a chain directly (i.e. not as a remote runnable), then the "get_openai_callback()" works well and picks up token spent and cost only when using the invoke method and having the "streaming=False" on the LLM side. When using the stream method,. then it does not work. Is there maybe an example our there for tracking the token spent and costs with a RemoteRunnable? Would be great if that could be resolved (server side OK as well), as hard to go to production without it. Thx


### ▷ #[share-your-work](https://discord.com/channels/1038097195422978059/1038097372695236729) (2 messages): 
        
- **LLama-CPP-Chat-Memory**: User `@discossi` has developed a character AI chatbot using langchain, chainlit, and chroma which supports text, pdf, and json documents, as well as metadata filtering with json documents. The project is housed on [GitHub](https://github.com/ossirytk/llama-cpp-chat-memory) and is designed to be a simple, lightweight tool for developers. Currently, work is underway on automatic metadata creation from documents with Natural Entity Recognition.
- **Python Lessons for AI Application Development**: User `@rajib2189` has started publishing Python lessons, starting from basics and gradually incorporating more advanced topics. The lessons are intended to help anyone interested in developing AI applications, including LLM-based ones. The content is available on [YouTube](https://www.youtube.com/playlist?list=PL1eVNGcrHFPfZjsKzGpfW9mJIJaUcyIjN), in line with the belief in knowledge currency and open source. A suggestion was made for collaborative learning to leverage mass intelligence.


        

---

## [Alignment Lab AI](https://discord.com/channels/1087862276448595968) Discord Summary

- **Humoristic Proposal and Discussion** in general-chat: An amusing suggestion by `@rusch` about an "adopt-a-token" donation drive for compute resources was discussed; led to an explanation comparing crypto tokens and text tokens in language models like Long Short-Term Memory (LLM).
- **UnSloth vs OpenChat Comparison**: `@imonenext` stated that UnSloth was "*4X slower than openchat*" in the oo channel. An estimate was provided indicating that full Orca GPT4 training would take approximately 774 hours on UnSloth compared to 48 hours on OpenChat.
- **UnSloth's Limitations and Usability**: Criticisms were made by `@ufghfigchv` about UnSloth's single GPU limitation, along with a remark by `@jeremyhoward` that "*Unsloth is specifically for Lora*", suggesting its usage is more specific rather than general.
- **Discourse on Monetization**: Possible monetization strategies, including premium features and hosted training, were discussed between `@imonenext` and `@caseus_` in the oo channel. Concern was voiced by `@giftedgummybee` about alienating the open source community with paywalled features.
- **Concerns Over Potential Competition**: In the context of monetization strategies, `@giftedgummybee` pointed out potential competition from Azure in hosted training.
- **Hopes for Orca-2 Dataset Release**: In oo2 channel, `@caseus_` expressed hope for the release of the Orca-2 dataset, sharing the link: [https://fxtwitter.com/winglian/status/1731169945461932203](https://fxtwitter.com/winglian/status/1731169945461932203).

**Alignment Lab AI Channel Summaries**

### ▷ #[general-chat](https://discord.com/channels/1087862276448595968/1095458248712265841) (4 messages): 
        
- **Adopt-a-token donation drive for compute**: User `@rusch` made a humorous suggestion about the possibility of having a donation drive for compute resources where each donor could "adopt" a text token. The phrase "adopt-a-token" is a play on terms comparing text tokens in language models and crypto tokens.
- **Discussion on tokenizing text for an LLM**: User `@ufghfigchv` had some difficulty understanding `@rusch`'s joke, leading to a brief explanation about the comparison between crypto tokens and text tokenizing for Long Short-Term Memory (LLM) models. They concluded the chat joking about the potential difficulties of training a model with over a million token tokenizers.


### ▷ #[oo](https://discord.com/channels/1087862276448595968/1118217717984530553) (31 messages): 
        
- **Comparative Speed of UnSloth and OpenChat**: `@imonenext` noted, "*unsloth is still 4X slower than openchat*". This was affirmed by a calculation showing that training full Orca GPT4 would take approximately 774 hours on UnSloth, as opposed to 48 hours on OpenChat.
- **Single GPU Limitation of UnSloth**: `@ufghfigchv` pointed out that UnSloth is less useful due to its single GPU limitation, suggesting this free version is a promotional tool for more capable, paid versions.
- **UnSloth's Fit for Lora**: `@jeremyhoward` mentioned that "*Unsloth is specifically for Lora*", indicating that its use may be more targeted rather than generally applicable.
- **Monetization Discussion**: `@imonenext` and `@caseus_` discussed potential monetization strategies, including premium features and hosted training. However, `@giftedgummybee` cautioned against alienating open source community by paywalling certain features, suggesting leveraging and providing support could be a better approach. 
- **Strategy Against Competition**: `@giftedgummybee` also highlighted potential competition from Azure in the hosted training sector, implying the need for strategic considerations in this area.


### ▷ #[oo2](https://discord.com/channels/1087862276448595968/1176548760814375022) (1 messages): 
        
caseus_: Hopefully they'll consider releasing the Orca-2 dataset sans answers. 🤞🏽
https://fxtwitter.com/winglian/status/1731169945461932203


        

---

## [Latent Space](https://discord.com/channels/822583790773862470) Discord Summary

Only 1 channel had activity, so no need to summarize...

[object Object]
        

---

## [LLM Perf Enthusiasts AI](https://discord.com/channels/1168579740391710851) Discord Summary

- Discussion on the **generation of proposals with OpenAI API** for creating formal PDFs with fixed and variable data. Members suggested the use of *prompt chaining* and feeding the machine the prompt in *markdown with links* for better data comprehension. Observations on synth dataset creation with GPT-4-0314's potential of generating working links were made.
- Queries and observations related to **Azure's gpt-4-1106-preview experience** and noted the recent increase in OpenAI call latency.
- Link sharing of notable **open-source projects**: [Unsloth](https://github.com/unslothai/unsloth), promising faster finetuning and reduced memory use, and [GPT-fast](https://pytorch.org/blog/accelerating-generative-ai-2), boasting a llama2-7b model with impressive token/s speed.
- Positive **user experience with AWS textract** in handling tables, commending its accuracy, speed, and reliability.
- Question on the application of **chain of verification** to improve the reliability of orchestrating an agent.
- Introduction of a **prompt hacking challenge game with LLMs** accessible at [https://gandalf.lakera.ai/](https://gandalf.lakera.ai/), involving the engagement of two LLMs in password reveal prevention.

**LLM Perf Enthusiasts AI Channel Summaries**

### ▷ #[general](https://discord.com/channels/1168579740391710851/1168579740391710855) (5 messages): 
        
- **Generation of Proposals using OpenAI API**: User `@frandecam` is looking for a way to generate formal proposals as PDFs with fixed and variable data using OpenAI API. The variable data would be produced by the LLM (pricing, inventory, etc).
- **Suggestion of Prompt Chaining**: `@wenquai` suggests using prompt chaining for generating larger pieces of content.
- **Possible Usage of Markdown with Links for Generation**: `@robotums` suggests using markdown with links for generation. Converting the prompt into markdown and feeding it with existing links can make LLM copy the link appropriately.
- **Remark on Dataset and GPT-4-0314**: `@robotums` notes that during the synth dataset creation, they observed GPT-4-0314 hallucinate working links on news articles written after its training date.
- **Unfinished Message from @jeffreyw128**: The conversation ends with a message from `@jeffreyw128` that seems incomplete.


### ▷ #[gpt4](https://discord.com/channels/1168579740391710851/1168582188950896641) (2 messages): 
        
- **GPT-4-1106-Preview Experience Inquiry**: `@sourya4` asked the community if anyone had used **gpt-4-1106-preview** on Azure and wanted to understand their experience.
- **Azure OpenAI Call Latency**: `@sourya4` shared an observation regarding an **increase in latency** of Azure OpenAI calls in recent weeks.


### ▷ #[opensource](https://discord.com/channels/1168579740391710851/1168606773595349082) (1 messages): 
        
lhl: a couple interesting projects worth sharing. https://github.com/unslothai/unsloth "80% faster 50% less memory local QLoRA finetuning" and gpt-fast: https://pytorch.org/blog/accelerating-generative-ai-2 - llama2-7b @ 246 tok/s is no joke


### ▷ #[speed](https://discord.com/channels/1168579740391710851/1168986766607384638) (1 messages): 
        
daymanfan: Been using AWS textract for tables, 100% accuracy, fast and reliable


### ▷ #[reliability](https://discord.com/channels/1168579740391710851/1169378117865963580) (1 messages): 
        
sourya4: Has anyone used chain of verification in improving reliability of orchestrating an agent?


### ▷ #[irl](https://discord.com/channels/1168579740391710851/1171569983688560732) (1 messages): 
        
luca1442: 🇨🇭 Yes 🙌


### ▷ #[prompting](https://discord.com/channels/1168579740391710851/1179271229593624677) (2 messages): 
        
- **Prompt Hacking Challenge with LLMs**: `@thebaghdaddy` shared a prompt hacking game where users need to **prompt hack an LLM to not reveal a password** while a second LLM screens the outputs. The game is available at [https://gandalf.lakera.ai/](https://gandalf.lakera.ai/).


        

---

## [MLOps @Chipro](https://discord.com/channels/814557108065534033) Discord Summary

- **Samantha Models Updates Inquiry**: User `@elbios` requested information on a 'version log' or changelog for Samantha models in the `#events` channel. Response from user `@faldore` indicated the absence of a specific change log, suggesting model cards and blog posts as resources for updates and change history.
- **Query on Learning Resources for LLMs**: In the `#general-ml` channel, `@samsamiczy` asked for recommendations on resources to learn about **Language Models (LLMs)**, assuming a substantial understanding of **Natural Language Processing (NLP)** up to 2022 and familiarity with transformer, GPT models, BERT, etc. No specific resources were provided in the shared messages.


**MLOps @Chipro Channel Summaries**

### ▷ #[events](https://discord.com/channels/814557108065534033/869270934773727272) (4 messages): 
        
- **Samantha Models Inquiry**: User `@elbios` inquired about a 'version log' or changelog for Samantha models. User `@faldore` replied that there isn't a specific change log, however, mentions that **model cards** and **blog posts** serve as sources for updates and change history.


### ▷ #[general-ml](https://discord.com/channels/814557108065534033/828325357102432327) (2 messages): 
        
- **LLMs Self-learning Resources Query**: `@samsamiczy` asked for recommendations on resources to learn **LLMs** assuming a decent knowledge of **NLP until 2022**, including understanding of transformer, **GPT models, BERT etc**. There was no response provided in the provided messages.


        

---

## [Ontocord (MDEL discord)](https://discord.com/channels/1147858054231105577) Discord Summary

Only 1 channel had activity, so no need to summarize...

[object Object]
        

---

## [AI Engineer Foundation](https://discord.com/channels/1144960932196401252) Discord Summary

Only 1 channel had activity, so no need to summarize...

[object Object]
        

---
The Skunkworks AI Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

---
The Perplexity AI Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

---
The YAIG (a16z Infra) Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.