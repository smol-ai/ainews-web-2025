---
id: 518d68f0-1882-410b-b0b1-91667d406742
title: '[AINews] AI Discords Newsletter  11/27/2023'
date: '2023-11-27T21:40:01.012711Z'
status: sent
type: public
source: api
metadata: {}
original_slug: ainews-ai-discords-newsletter-11272023
---

<!-- buttondown-editor-mode: plaintext -->
## [Latent Space](https://discord.com/channels/822583790773862470) Discord Summary

Only 1 channel had activity, so no need to summarize...

**Latent Space Channel Summaries**

### â–· Channel: [ai-general-chat](https://discord.com/channels/822583790773862470/1075282825051385876) (6 messages): 

- **Meetup Organization**: User `@ivanleomk` is organizing a round of drinks for members in Singapore. The RSVP link is provided in the chat. User `@eugeneyan` expressed their enthusiasm for the upcoming event.
- **GPT captcha Issue**: User `@kb.v01` mentioned the recurrence of the captcha using a custom GPT, questioning if there are still scaling issues. 
- **Resources on GPT-4 Variants**: User `@jozexotic` asked for resources explaining the behaviors and results of the `GPT-4` variants including `GPT-4-0613` and `GPT-4-Turbo`.
- **User Report**: User `@jozexotic` reported inconsistent performance differences among the `GPT-4` versions, stating the performance differences are neither 'better' nor 'worse' but dependent on the use case.
- **Event Announcement**: User `@slono` shared a link to the `https://codeforward.ai` event asking if anyone is going. 

Links:
- [Singapore meetup RSVP](https://lu.ma/ml-llm-beers)
- [Codefoward.ai event](https://codeforward.ai)
        

---

## [OpenAI](https://discord.com/channels/974519864045756446) Discord Summary

- **Discussion on AI's Consciousness and Emulation**: Key topics included the possibility of attributing consciousness as a universal property, the comparison between humans and AI as different levels of consciousness emulators, the role of mimicry in perceived emotion or feeling, and the pragmatic understanding of true emotions through genuine experiences.
- **Detailed Debate on AI's Capabilities**: Conflicting viewpoints on the categorization of models like GPT-3 as AI, and an investigation into the capabilities and limitations of AI in terms of autonomy, self-improvement, learning, skepticism, and dependence on human instruction.
- **Exploration of Custom-Made AI and AI Art**: Discussions on how freelance designers might monetize work using AI, the commercial viability and uniqueness of AI-generated art, and contrasting opinions about the potential of AI art based on personal experience.
- **Inquiry about AI's Job Replacing Potential**: Conversation on the potential implications of recent troubles at OpenAI on perceptions of AI's ability to replace human jobs, emphasizing the need for backup plans and alternatives due to potential instability.
- **Guidance Request for AI Development**: User desire for learning resources expressed, though the request remained unanswered.
- **Delving into GPT-4 and Assistant Playground**: Multiple users had discussions on enabling GPT-4 in the playground, billing concerns, and the various capabilities and limitations of the model. 
- **Awareness around Disallowed Uses of AI Models**: Cautionary note about OpenAI's policy on disallowed usages, particularly in the context of legal purposes.
- **User Experiences with ChatGPT**: Conversation on the application of ChatGPT in hobby-related activities, like Dungeons & Dragons game preparations and occasional server issues experienced by users while accessing the service.
- **Interactive Debates on AI Capabilities**: Friendly debates on topics such as ChatGPT's efficiency and practicality in various contexts.
- **Convention on Usage Limits, Authentication and Limitations of AI**: Users engaged in discussions about the usage limits of custom and standard GPTs, potential workarounds, integration of Zapier action into the GPT model, troubleshooting GPT's story continuation, user authentication concerns, and the limitations of AI models.
- **Dynamic Discussion on GPT-4**: Chat about network issues preventing GPT-4 access, model output and token limits, troubleshooting ChatGPT issues, adoption of character traits by GPT agents, file import limits for Custom GPTs, and various introductions and creations of new GPT models.
- **Prompt Engineering Discourse**: Points discussed included the benefits of training GPTs with Markdown, the limitations of custom GPTs in using knowledge bases effectively, crafting controversial comments, strategies for securing information with GPTs, and exploration of persistently running scripts for complex tasks.
- **OpenAI API Discussions**: Topics such as efficacious use of Markdown with GPT, managing GPT output in JSON and challenges with the assistant API, issues around custom GPT inefficiency, guidance on improved usage of knowledge base, issues and potential solutions related to GPT state management, and an innovative example of text adventures visualized in a strategy game.

**OpenAI Channel Summaries**

### â–· Channel: [ai-discussions](https://discord.com/channels/974519864045756446/998381918976479273) (407 messagesðŸ”¥): 

- **Discussion on AI's Consciousness and Emulation**: Users `@simple_chad`, `@mikeloots`, and `.dooz` had an engaging discussion on consciousness in AI and humans. In simple_chad's view, consciousness could be attributed as a property of the universe, and humans and AI are both emulators of that consciousness but at different levels of complexity and capabilities. `.dooz` raised the idea that perfect mimicry can be perceived as equivalent to actual emotion or feeling, even if the 'understanding' or consciousness behind it is not the same as in humans. In response, mikeloots emphasized that truly understanding emotions requires genuine experience of them, something AI lacks at present.

- **Debate on AI and its Capabilities**: `@venkolm` argued that GPT-3 isn't AI because it isn't autonomous or self-improving. He believes AI isn't capable of genuine learning or skepticism and needs continuous instruction from humans. `@ted_k`, `.dooz`, and `@simple_chad` disagreed, asserting that GPT-3 and comparable models are indeed AI, citing aspects like token prediction and incorporation of massive amounts of training data as key factors.

- **Exploration of Custom-made AIs and AI Art**: `@foxy_mcdick` brought up how freelance designers might monetize work using the Midjourney image generator. `@venkolm` and `@.pythagoras` exchange viewpoints on the commercial viability and uniqueness of AI-generated art, with the former skeptical and the latter optimistic based on personal experience. 

- **Inquiry about AI's Job Replacing Potential**: `@mrsyntax` raised a question about whether the recent troubles at OpenAI have affected attitudes towards AI's potential to replace human jobs. `@eskcanta` responded with the opinion that such events highlight the uncertainties and potential instability of relying solely on AI, which could lead to an increased demand for backup plans and alternatives.

- **Request for Guidance on AI Development**: `@satoru1815`, expressing a desire to return to learning AI development after a 12-year hiatus, asked the group for guidance on where to start. This received no responses during the chat history provided.


### â–· Channel: [openai-chatter](https://discord.com/channels/974519864045756446/977697652147892304) (407 messagesðŸ”¥): 

- **GPT-4 and Assistant Playground**: User `@ckobasti` had an extensive conversation with `@rjkmelb` and `.bytebug` about enabling GPT-4 in the Assistant playground. He learned that it requires adding credit under billing, and the GPT Plus and the API are separate products and billed separately. He also learned about various capabilities of the model, including reading from PDF files and scanning images, and the possibility of programming in any language.
- **List of Disallowed Uses of AI Models**: `@eskcanta` highlighted a section of OpenAI's policy around disallowed usage, specifically with regards to the usage of the AI for legal purposes, cautioning against any usage of the AI that could be perceived as offering tailored legal advice without a qualified person reviewing the information.
- **ChatGPT availability issue**: Different users (`@3dgeekshow`, `@alessiogr`, `@aar9506`, `@exaltist`) discussed having occasional issues logging in to ChatGPT due to busy servers but it resolved after retrying.
- **User discussions on using the AI to generate RPG content and other hobbies**: `@pruo` and `@lugui` mentioned that they used the platform to assist with the preparation for Dungeons and Dragons games. This included the generation of character backstories, creating random encounters, and general game support.
- Respectful and friendly interactions between channel members: The users had light-hearted discussions and debates regarding the AI's capabilities and limitations, and interacted in a friendly manner. This included topics ranging from ChatGPT's efficiency in auto completion to its practicality in a variety of scenarios.


### â–· Channel: [openai-questions](https://discord.com/channels/974519864045756446/974519864045756454) (226 messagesðŸ”¥): 

- **Custom GPT Development and Usage Limit**: Users `@d_smoov77`, `@stealth2077`, `@crerigan`, `@ericturner.`, and `@vipraz` engaged in a discussion on the usage limit of custom GPTs. They identified the separate usage limits for standard and custom GPTs, with the latter being slightly lower. Strategies or workarounds such as load balancing across multiple OpenAI accounts were suggested. `@solbus` referred to a [list of billable actions](https://discord.com/channels/974519864045756446/974519864045756454/1176537779996479549) that help understand the usage calculation in more detail.

- **Inserting Zapier Action into GPT**: `@danielnadeo_04361` asked for assistance in integrating a Zapier action into a GPT model. `@thesocraticbeard` suggested making an OpenAPI specification or adjusting instructions based on URL usage. Finally, they recommended using OpenAI's Assistants API to bring a GPT-like solution to a website, sharing the [assistants overview link](https://platform.openai.com/docs/assistants/overview) for reference.

- **GPT-Powered Story Continuation**: `@stealth2077` sought advice for getting GPT to continue a story. They reported that the Agent reads from somewhere in the middle of the uploaded text file rather than the end. To circumvent this, `@thesocraticbeard` suggested re-wording the instructions to make the agent start from the end of the text file.

- **GPT User Authentication Concerns**: `@phazei` asked if deleting their OpenAI account entirely would help change the authentication method, citing the difficulty logging into Google Accounts. Several users suggested contacting OpenAI support for resolution, and `@eskcanta` highlighted the support@openai.com email address.

- **Technical Limitations of AI**: `@thesocraticbeard` and `@zwischenzugs` drew attention to AI limitations, such as the inability of the AI model to directly access the internet or process tasks such as video editing or creating graphs from data. They also discussed the inability of the base GPT to modify its knowledge continually after initial training.

- **Other Discussions**: Various other conversations touched on issues such as a deactivated account, difficulties in using DALL-E, volume issues with the OpenAI call feature, and errors encountered while using the ChatGPT API. Some users also shared their experiences and obstacles while testing or developing their custom GPT models.


### â–· Channel: [gpt-4-discussions](https://discord.com/channels/974519864045756446/1001151820170801244) (76 messages): 

- **Network issues and restricted GPT-4 interface access**: User `@liming_60085` experienced network issues that restricted access to GPT-4. User `@solbus` redirected the user to other channels for discussion and troubleshooting.
- **Discussion on GPT Model Outputs and Token Limits**: `@truongtoan113` and `@lumirix` had a conversation about the number of tokens output by different GPT models. They discuss how certain models may be constrained by the CONTEXT WINDOW in outputting their responses but couldn't find documentation to back this up.
- **Troubleshooting ChatGPT issues**: `@mdehoque` encountered trouble querying PDF files uploaded to ChatGPT, with the system getting stuck at "Regenerate". 'Refreshing the page' was suggested as a solution, but the problem persisted.
- **Instructing GPT agents to adopt character traits**: `@patrickgamer` was improving the behavior of a GPT agent to adopt the personality traits of a Ferengi from Star Trek. After adding a bullet point emphasizing the agent to be "*not like a human*", a considerable change in the response was noticed.
- **File import limits for Custom GPT**: `@solbus` informed `@snowzer` that up to ten 512MB files can be imported into Custom GPT, providing a link to more information on the topic.
- **Introductions and New GPT Creations**: `@tunter.` and `@mikepaixao` introduced themselves and shared links to their created GPTs such as the "Lex Fridman Podcast" and "Great Sage".
- Users `@marta.m.p`, `@kolehti`, and `@satanhashtag` discussed the current wait time for access to ChatGPT 4. There was no definitive answer or ETA available.
- `@dotails` brought up a suggestion for adding the ability to switch back to GPT-4 from GPT 3.5 once the wait time is over. This feature is currently not available.


### â–· Channel: [prompt-engineering](https://discord.com/channels/974519864045756446/1046317269069864970) (25 messages): 

- **Training GPTs with Markdown and Plain Text**: In a discussion initiated by `@jungle_jo`, users highlighted that GPT has been trained on Markdown, and that using Markdown to guide it can be beneficial. `@eskcanta` also added that language fluency between user and AI contributes to effective communication. `@fran9000` and `@eskcanta` further discussed the use of plain text and line breaks in knowledge base files.
- **Limitations of GPTs**: `@johnz999` voiced concerns about inefficiencies in custom GPTs, specifically regarding their infrequent use of knowledge bases and incoherent responses.
- **Controversial Comments**: `@bambooshoots` critically addressed unknown user's lack of understanding about domain knowledge, prompt engineering, and LLMs.
- **Securing Information with GPTs**: `@eskcanta` explained the complexities involved in training an AI to both acknowledge and not share certain secrets. 
- **Persistent Python Script Possibilities**: A conversation led by `@fran9000` and `@eskcanta` explored the idea of a persistently running Python script that stores state data, especially for more complex or conditional tasks.


### â–· Channel: [api-discussions](https://discord.com/channels/974519864045756446/1046317269069864970) (25 messages): 

- **GPT and Markdown**: `@jungle_jo` queries about the effective use of Markdown with GPT. `@eskcanta` suggests using any language both the user and AI understand well.

- **GPT output in JSON format**: `@boomboom68` asks for prompts to restrict GPT-4 to produce output in JSON because the assistants API lacks a JSON mode.

- **Custom GPT inefficiency**: `@johnz999` comments on custom GPTs inefficiency, mentioning their issues with referencing the knowledge base correctly. Response by `@bambooshoots` criticizes these claims due to user misunderstanding and lack of expertise.

- **Knowledge Base Guidance**: `@eskcanta` shares insights on checking the knowledge base, providing clear instructions and avoiding conflicts. Also mentions their ongoing work on an improved SecretKeeperGPT aimed at resisting all possible trickery.

- **GPT state management**: `@fran9000` and `@eskcanta` discuss the challenge of managing GPT states and the value of getting/saving state data on a server. `@fran9000` also shares the details of their GPT based on the classic TV show "The Prisoner". 

- **Visualization of a text adventure**: `@stealth2077` provides an example of an in-text scenario for a strategy game, aiming to get GPT to visualize stats and not need to be reminded to generate stats and images.


        

---

## [LangChain AI](https://discord.com/channels/1038097195422978059) Discord Summary

- **Update on `langchain-core`** by `@bagatur`, noting the release of version `0.0.341` and its dependency on `langchain-core` `0.0.6`, with advice against direct usage of `langchain-core` until the `0.1` release. [Source](https://discord.com/channels/1038097195422978059/1058033358799655042)
- Discussion on the best strategy for using **Pinecone as a vector database backend**, considering either creating a new pod for each user or using two large pods and namespaces.
- Reported issue with **Inference API timeout on HuggingFaceHub** when trying to use a non-listed model for a RAG application.
- Inconsistencies with the **SERP API used with agents**, specifically yielding incorrect responses for certain basic queries.
- Issue with a **Data Manipulation Agent terminating at a `Thought` instead of reaching the `Final answer`** during JSON return operations.
- Consultation on building a **chatbot with context-relevant follow-up capabilities**, with recommendation to tailor the prompt accordingly.
- Inquiry on the correct procedure to scrape selective elements of a website using **UnstructuredURLLoader() in element mode**.
- Query on how to retrieve the response status code and specific HTTP headers from a non-200 response from the OpenAI API.
- Experienced issue with `RunnablePassthrough` in LangServe, which causes the disappearance of original fields, with a workaround provided.
- Inquiry and interest expressed towards **adding Django support** to Langserve for larger, scalable applications with ORM capability.
- Enablement of **callback event sending** from a LangServe server, with a linked parameter, and notice of limited testing and support only for invoke and batch.
- Solutions for unexpected behave by **type inference**, with recommendation to use the `with_types` function.
- Instructions for setting up a **Chat Widget in LangServe**, with notice of potential future changes to `output` key behavior. [Chat Widget Setup](https://github.com/langchain-ai/langserve/blob/bb7725036c3a30aed63ee50bfe7abaaf0e05c66f/examples/conversational_retrieval_chain/server.py#L90)
- Interest in keeping systems self-hosted and using **MongoDB with Retriever Docstore**, with successful document storage reported.
- Inquiry on how to set up **a Chainlit frontend using the Research Assistant template**.
- Request for assistance in specifying the `{lang}` parameter in a **Conversational Retrieval QA Chain** and issues with language output, even after manually setting the language.
- Sharing of **a Docker setup for the LangServe Research Assistant Template**, accessible from a GitHub link with future plans outlined. [Docker Setup](https://github.com/joshuasundance-swca/langchain-research-assistant-docker)
- Sharing of a thread on creating a **RAG Chain with Sources** using the LangChain expression language. [RAG Chain with Sources](https://x.com/waseemhnyc/status/1728889388954951717?s=20)

**LangChain AI Channel Summaries**

### â–· Channel: [announcements](https://discord.com/channels/1038097195422978059/1058033358799655042) (1 messages): 

- **Update on langchain-core**: `@bagatur` announced the release of the first version of langchain (`0.0.341`) that utilizes langchain-core (`0.0.6`). They mentioned that this update **shouldn't affect the usage of `langchain`** and advised not to switch application code to using langchain-core directly until the release of langchain-core `0.1`, which is **scheduled for 12/8**. Users have been urged to report any issues they encounter with the new release.


### â–· Channel: [general](https://discord.com/channels/1038097195422978059/1038097196224086148) (17 messages): 

- **Use of Pinecone as Vector Database Backend**: `@sullynaj` asked about the best approach to using Pinecone as the vector database backend in their platform. Specifically, they are considering whether to create a new pod for each new user or to use two large pods and namespaces for all users.
- **Inference API timeout with HuggingFaceHub**: `@kamlesh` experienced an Inference API timeout when trying to use a model not available in langchain's HuggingFaceHub list for a RAG application.
- **SERP API Usage with Agents**: `@sid.pocketmail` was having inconsistencies with the SERP API when used with agents. They reported receiving incorrect responses for certain simple questions.
- **Data Manipulation Agent Stopping at a Thought**: `@_lawgic` is leveraging an agent for data manipulation tasks intended to return JSON at each step. They have encountered an issue where the agent sometimes ends at a `Thought` instead of reaching the `Final answer`.
- **Building a Chatbot with Follow-Ups**: `@._.nobody._._` sought advice on developing a chatbot capable of asking contextually relevant follow-up questions. `@seththunder` suggested tailoring the prompt to include an instruction for asking follow-up questions.
- **Web Scraping Query**: `@diegoru98` asked for guidance on scraping selective elements from a website using the UnstructuredURLLoader() in element mode. 
- **Retrieve Response Status and HTTP headers**: `@wyang14` asked how to fetch the response status code and specific HTTP headers from a non-200 response from the OpenAI API.


### â–· Channel: [langserve](https://discord.com/channels/1038097195422978059/1170024642245832774) (7 messages): 

- **Issues with `RunnablePassthrough` in LangServe**: User `@abalog_92335` reported an issue where running a `RunnablePassthrough` with LangServe causes **original fields to disappear**. A solution was found by placing a `RunnablePassthrough()` before and after the main chain. The user expressed a desire to understand why this solution works and how to use it in a more "proper" way.
- **Interest in Django Support**: User `@veryboldbagel` inquired about the community's interest level in adding Django support, and `@aliikhatami94` expressed a lot of interest to support large, scalable applications with an ORM capability.
- **Enabling Callback Event from the Server**: `@veryboldbagel` highlighted the ability to enable callback event sending from the server using this [parameter](https://github.com/langchain-ai/langserve/blob/main/langserve/server.py#L470) and admitted its feature is not well tested. It was also mentioned that this is only supported for invoke and batch.
- **Solving Type Inference Issue**: To address a situation where type inference acted unexpectedly, `@veryboldbagel` suggested using the `with_types` function to specify the expected inputs, as demonstrated in the mentioned [code snippet](https://github.com/langchain-ai/langserve/blob/af904f5f6e3418b0e776bad1b0c5911f367bd7b7/examples/agent/server.py#L77-L77).
- **Chat Widget Setup**: `@veryboldbagel` provided a link to the code for setting up a chat widget in LangServe but cautioned users that the behavior of the `output` key will likely change in the future, resulting in a breaking change. The link to set up a chat widget is [here](https://github.com/langchain-ai/langserve/blob/bb7725036c3a30aed63ee50bfe7abaaf0e05c66f/examples/conversational_retrieval_chain/server.py#L90).


### â–· Channel: [langchain-templates](https://discord.com/channels/1038097195422978059/1170025009960456282) (4 messages): 

- **Self-hosting and Using MongoDB with Retriever Docstore**: User `@alex_35579` expressed a desire to keep things self-hosted and expressed interest in directly referring to MongoDB in the Retriever Docstore for convenience. They confirmed that they had MongoDB working and were able to store documents within it.
  
- **Setting up a Chainlit Frontend with Research Assistant Template**: User `@0ymika` inquired about how to set up a Chainlit frontend utilizing the Research Assistant template.

- **Code Help for Specifying Language Parameter in Conversational Retrieval QA Chain**: User `@menny9762` requested assistance with their Javascript code for a Conversational Retrieval QA Chain. They were specifically struggling with specifying the `{lang}` parameters and also mentioned that even when they manually set the language, the response often came in English. The said code, including the QA_PROMPT constant and creation of the Retrieval QA Chain, was provided within the post.


### â–· Channel: [share-your-work](https://discord.com/channels/1038097195422978059/1038097372695236729) (1 messages): 

- **Docker Setup for Langserve Research Assistant Template**: `@joshuasundance` has shared a simple Docker setup to experiment with the Research Assistant Template using Langserve. The Docker setup can be accessed from [this GitHub link](https://github.com/joshuasundance-swca/langchain-research-assistant-docker). Future plans include pushing the setup to DockerHub and adding an OpenAI key to the Kubernetes yaml file.


### â–· Channel: [tutorials](https://discord.com/channels/1038097195422978059/1077843317657706538) (1 messages): 

- **RAG Chain with Sources**: User `@wassup6526` shared a thread about how to create a **RAG Chain with Sources** using the LangChain expression language. The thread can be accessed through the provided link [https://x.com/waseemhnyc/status/1728889388954951717?s=20](https://x.com/waseemhnyc/status/1728889388954951717?s=20).


        

---

## [Nous Research AI](https://discord.com/channels/1053877538025386074) Discord Summary

- In-depth discussions on **AI model performance and training strategies** occurred across the guild:
    - `@euclaise` discusses balancing subjective performance gains with potential benchmark score losses during model training. 
    - `@danielpgonzalez` proposes a method for improving beam search run in parallel and evaluates using a Large Language Model. 
    - `@yorth_night` suggests fine-tuning a base Arabic model on the Moroccan dialect for models designed for low resource languages. 
    - `@giftedgummybee` advises limited epochs to avoid overfitting on data-constrained datasets.
    - `@teknium` recommends tried and tested model parameters for running latest OpenHermes models in LM Studio. 

- Multiple new AI Models such as **Goliath, Hermes, and Koishi** were highlighted by `@ludis___` and `@nonameusr`, detailing their individual capacities and potential combinations.

- `@nonameusr` initiated an insightful dialogue on **enhancing AI teachability and experiential learning**, highlighting strategies like iterative learning, self-initiated thought, and improved information retrieval.

- Usage of **Reward Models** in AI training was examined, with `@teknium`endorsing their enhanced scoring capabilities. `@casper_ai` revealed successful application of Starling-RM-7B-alpha reward model to refine Mistral 7B.

- Model comparisons noted by `@orabazes` and `@variav3030`, favoring **OpenHermes** over variants of **Capybara**.

- Practical issues raised included `@kdawgdfw` seeking advice on llama.cpp, `@nonameusr` inquiring about accessing Huggingface's training datasets, and `@latentfog` querying about multiple evaluation datasets in Huggingface trainers.

- Interesting issues and ideas outside the technical domain, such as dream experiences of technical work, the desire for brand swag, and advice on avoiding travel scams encountered while studying low resource languages.

- A plethora of topical links was shared across multiple topics, like AI research papers, GitHub repositories, YouTube videos, and tweets. These inclusive of specific links like [Mergekit Tool](https://github.com/cg123/mergekit), [cDPO Technique Paper](https://ericmitchell.ai/cdpo.pdf), and [Starling-RM-7B-alpha](insert hypothetical link here).

**Nous Research AI Channel Summaries**

### â–· Channel: [ctx-length-research](https://discord.com/channels/1053877538025386074/1108104624482812015) (2 messages): 

- **Expressivity of the Attention Mechanism**: `@euclaise` mentioned that **reducing the expressivity of the attention mechanism** might not have any negative impact.
- **RNNs Before Transformer**: `@euclaise` suggested a solution of adding RNNs before the transformer and shared a link to a related research paper titled "Recurrent Transformers for Speech Recognition".
   - Link: [Recurrent Transformers for Speech Recognition Paper](https://arxiv.org/pdf/2006.10220.pdf)


### â–· Channel: [off-topic](https://discord.com/channels/1053877538025386074/1109649177689980928) (18 messages): 

- **Formatting of Hermes**: `@teknium` pointed out an issue with the formatting in **Hermes**.
- **Scraping Pipeline Issue**: `@tsunemoto` mentioned that something was odd with his scraping pipeline and that they are currently working on it.
- **Nous Research Stickers**: Both `@imchrismayfield` made a request for Nous Research stickers for their laptops, which `@teknium` promised to bring to the Ollama event.
- **Dream and Nightmare Discussions**: There were discussions about dreams related to technical work. `@yorth_night` shared that they dream about full arXiv papers and `@somewheresy` and `@yorth_night` mentioned nightmares about Node dependency and CORS issues.
- Links shared:
    - [YouTube video shared by @fullstack6209](https://youtu.be/Qr1PgL79deQ?t=5190)
    - [YouTube video shared by @pradeep1148](https://youtu.be/Fff0Cl9_bMc)


### â–· Channel: [interesting-links](https://discord.com/channels/1053877538025386074/1132352574750728192) (9 messages): 

- User `@fullstack6209` shared multiple resources:
    - A guide on dealing with limited GPU resources: [GPU for the Poor](https://rahulschand.github.io/gpu_poor/)
    - An OpenReview research paper: [OpenReview Paper](https://openreview.net/forum?id=WFYbBOEOtv)
    - A YouTube video: [YouTube Video](https://www.youtube.com/watch?v=jSdHmImyUjk)
    - A GitHub repository named IJEPA by Facebook Research: [IJEPA](https://github.com/facebookresearch/ijepa)

- User `@_automagic` provided two links:
    - An unspecified link: [Link](https://t.co/k3YmrODJI3)
    - A tweet found interesting: [Tweet](https://x.com/fluffykittnmeow/status/1729072654420680908)

- `@firefox8975` shared a Twitter link: [Tweet](https://x.com/amanrsanger/status/1728877972156031033?s=46&t=RfcU4U4JKoN7CC8v9Rnvog)

- `@metaldragon01` shared a tweet from user banghuaz: [Tweet](https://fxtwitter.com/banghuaz/status/1729174022251020387)


### â–· Channel: [general](https://discord.com/channels/1053877538025386074/1149866623109439599) (211 messagesðŸ”¥): 

- **Model Performance and Training Discussions**: `@euclaise` discussed the training of AI models, mentioning that training on one prompt format might reduce benchmark scores but improve subjective performance. `@danielpgonzalez` proposed a method improving beam search by running multiple beams in parallel and using an LLM (Large Language Model) to evaluate the quality of each beam. 
- **Goliath, Hermes, and Koishi Models**: `@ludis___` introduced **Goliath**, a 120b model produced by merging two **Llama2 70b models**. `@nonameusr` described initial tests done on Goliath and recommended fixing censorship issues. `@ludis___` confirmed plans to fix this issue and also revealed the name of another AI model in development, called **Koishi**. The idea of merging the **OpenHermes 2.5** with **Nous Capybara 34b** and Koishi to create a 161b model was suggested.
- **Discussion on AI Teachability and Experience**: Various users, namely `@nonameusr`, used the chat to discuss about making AI models more teachable and aware. The discussion covered ideas such as reiterative learning, self-initiated thought, linking previous lessons to create a more cohesive educational experience for the user, and enhancing creativity and information retrieval simultaneously.
- **Reward Model Discussion**: A conversation took place regarding the use and efficacy of Reward Models in AI training. `@teknium` suggested that reward models were capable of better scoring and reasoning. `@thepok` suggested trying out APA, PPO, and P3O techniques and noted that online training yields better results than offline training, despite being more challenging. `@casper_ai` mentioned the release of the **Starling-RM-7B-alpha** reward model, and highlighted their use of this reward model to fine-tune Mistral 7B.
- **Links of Interest**: Several links and resources were shared:
    - [Mergekit Tool](https://github.com/cg123/mergekit)
    - [Reddit Link for LLM Comparison Test](https://www.reddit.com/r/LocalLLaMA/comments/17vcr9d/llm_comparisontest_2x_34b_yi_dolphin_nous/)
    - [cDPO Technique Paper](https://ericmitchell.ai/cdpo.pdf)
    - [Tweet on MT-Bench Score](https://fxtwitter.com/banghuaz/status/1729174022251020387?s=46&t=QUL78vIQDJohFpnIzCbQXA)


### â–· Channel: [ask-about-llms](https://discord.com/channels/1053877538025386074/1154120232051408927) (63 messages): 

- **Performances of Different Models**: Various users including `@orabazes` and `@variav3030` discussed the effectiveness of different AI models. It was stated that certain versions of **OpenHermes** appear to perform better overall compared to **Capybara-Yi** and **Capybara-Tess-Yi-200k-dare-ties**. `@_automagic` noted that **LoRa** performed slower when sufficient VRAM is available, as confirmed in a shared [link](https://x.com/capetorch/status/1728731759075119572). 
- **Downloading Data from Huggingface**: `@nonameusr` inquired about downloading training data for models on Huggingface. `@yorth_night` explained that this can be done by accessing the datasets a model was trained on, provided they have been made public by the model creator. 
- **Multiple Evaluation Datasets in Huggingface Trainers**: `@latentfog` sought advice on how to use multiple evaluation datasets in Huggingface trainers, noting that it seems accelerate is the only available option currently.
- **Efficient Training for Low Resource Languages**: `@yorth_night` and `@russselm` had an extended discussion about developing a model to understand the Moroccan dialect. They decided on starting with a base model trained on Arabic and then finely tuning this on the Moroccan dialect. Several epochs were suggested for this training, with `@giftedgummybee` advising a final set of 4 epochs for data-constrained datasets to avoid overfitting. The idea of synthetic data generation was also discussed, alongside tips for avoiding scams while travelling in Morocco.
- **Running LLMs with Llama.cpp**: `@kdawgdfw` requested advice on working with llama.cpp, in particular about the ideal command line arguments for running the latest OpenHermes. `@teknium` recommended default arguments used in LM Studio.


        

---

## [Alignment Lab AI](https://discord.com/channels/1087862276448595968) Discord Summary

- In the **ai-and-ml-discussion** channel, *`@hoshi_hiyouga`* brought up the use of a **re-rank technique**. In response, *`@spirit_from_germany`* requested more context or information on the topic. 
- In the **oo** channel, user *`@cryptossssun`* shared a research paper: [https://arxiv.org/pdf/2311.12023.pdf](https://arxiv.org/pdf/2311.12023.pdf).
- There was no noteworthy discussion in the **general-chat** channel to summarize.

**Alignment Lab AI Channel Summaries**

### â–· Channel: [ai-and-ml-discussion](https://discord.com/channels/1087862276448595968/1087876677603958804) (2 messages): 

- `@hoshi_hiyouga` mentioned the use of a **re-rank technique** in an unspecified context.
- `@spirit_from_germany` requested a link for more context or additional information on the topic.


### â–· Channel: [general-chat](https://discord.com/channels/1087862276448595968/1095458248712265841) (1 messages): 

The channel has no messages for the summarizer AI to summarize.


### â–· Channel: [oo](https://discord.com/channels/1087862276448595968/1118217717984530553) (1 messages): 

- A user `@cryptossssun` shared a link to a research paper: [https://arxiv.org/pdf/2311.12023.pdf](https://arxiv.org/pdf/2311.12023.pdf).


        

---

## [Skunkworks AI](https://discord.com/channels/1131084849432768614) Discord Summary

Only 1 channel had activity, so no need to summarize...

**Skunkworks AI Channel Summaries**

### â–· Channel: [off-topic](https://discord.com/channels/1131084849432768614/1140423597454807179) (1 messages): 

- A user, `@pradeep1148`, shared a YouTube link: [https://youtu.be/Fff0Cl9_bMc](https://youtu.be/Fff0Cl9_bMc). The topic or content of the video was not discussed.
        

---

## [LLM Perf Enthusiasts AI](https://discord.com/channels/1168579740391710851) Discord Summary

- A speculative but potentially **unhinged and untrue** document on **Q*** was shared by `@res6969` in the [Google Docs Link](https://docs.google.com/document/u/0/d/1RyVP2i9wlQkpotvMXWJES7ATKXjUTIwW2ASVxApDAsA/mobilebasic).

- Discussion related to finding a **faster alternative to SerpAPI** initiated by `@23goat`, with `@potrock` suggesting Metaphor as a possible solution, though noted that queries would have to be redone. A [link](https://x.com/amanrsanger/status/1728877972156031033?s=46&t=RfcU4U4JKoN7CC8v9Rnvog) was provided by `@firefox8975`.

- `@rabiat` shared a **job opportunity** for an **AI Engineer** at **SynthFlow.ai**, a company working on AI accessibility and building AI voice agents for B2B clients. The [AI Engineer job post](https://www.notion.so/synthflowai/AI-Engineer-d278f99739274fbf952c67dd7b1e26ba) is available for more details.

- A conversation about real-life **meetups** in **New York City** was initiated by `@robotums` and `@.psychickoala`, with an interest shown by `@minimario`. `@ivanleomk` also suggested a meetup in Singapore and shared an [RSVP link](https://lu.ma/ml-llm-beers) for the event.

- Intricate discussions about **GPTs and prompt engineering**, with `@jmtqjmt` voicing concerns over their approximately 15 GPTs' sensitivity to prompt engineering. A [YouTube video](https://youtu.be/pq34V_V5j18?si=9K5Ob0RTCsfwZdvw) for additional insights and a [cookbook tutorial](https://cookbook.openai.com/examples/assistants_api_overview_python) suggested by `@daymanfan` for understanding the mentioned video.


**LLM Perf Enthusiasts AI Channel Summaries**

### â–· Channel: [opensource](https://discord.com/channels/1168579740391710851/1168606773595349082) (1 messages): 

Apologies, but the message from `@joschkabraun` is incomplete and no specific discussion or topic has been provided to be summarized. Without complete information, a summary cannot be provided.


### â–· Channel: [offtopic](https://discord.com/channels/1168579740391710851/1168762388586176594) (5 messages): 

- **Q* Speculation Document**: User `@res6969` shared a [Google document](https://docs.google.com/document/u/0/d/1RyVP2i9wlQkpotvMXWJES7ATKXjUTIwW2ASVxApDAsA/mobilebasic) related to speculation on **Q***. The user noted that the speculation is potentially **unhinged and untrue** but found it interesting.


### â–· Channel: [speed](https://discord.com/channels/1168579740391710851/1168986766607384638) (3 messages): 

- **Searching for faster alternatives to SerpApi**: User `@23goat` asked for a faster alternative to [SerpAPI](https://serpapi.com) as it currently takes ~2-3s to retrieve the top 5 links for a query.
- **Suggestion for Metaphor as an alternative**: `@potrock` suggested using Metaphor instead of Google serp but noted that queries would have to be redone.
- **Link shared by firefox8975**: A [link](https://x.com/amanrsanger/status/1728877972156031033?s=46&t=RfcU4U4JKoN7CC8v9Rnvog) was shared by `@firefox8975`.


### â–· Channel: [jobs](https://discord.com/channels/1168579740391710851/1169107992587812864) (1 messages): 

- **Job Opening at Synthflow.ai**: User `@rabiat` shared that **Synthflow.ai** is hiring an **AI Engineer** to join their team to lead product development, research, and technical architecture for their new AI-powered platform. The company focuses on making AI accessible to everyone, and their platform helps B2B clients build AI Voice agents.
  - Link: [AI Engineer job post](https://www.notion.so/synthflowai/AI-Engineer-d278f99739274fbf952c67dd7b1e26ba)


### â–· Channel: [irl](https://discord.com/channels/1168579740391710851/1171569983688560732) (5 messages): 

- **New York City Meetup Discussion**: Users `@robotums` and `@.psychickoala` initiated a conversation about hosting a meetup in **New York City**. User `@minimario` expressed interest but mentioned a planned trip to Singapore in early December.
- **Singapore Meetup Planning**: User `@ivanleomk` proposed organizing a meetup for Singapore users and shared an RSVP link for the event. You can access it [here](https://lu.ma/ml-llm-beers).


### â–· Channel: [openai](https://discord.com/channels/1168579740391710851/1171903046612160632) (3 messages): 

- **Use of GPTs and prompt engineering**: In a conversation, `@jmtqjmt` mentioned the high sensitivity of their approximately **15 GPTs to prompt engineering**, and queried the approach to actions though they haven't explored them in detail.
- **Video Resources**: 
    - `@jmtqjmt` is also following a [YouTube video](https://youtu.be/pq34V_V5j18?si=9K5Ob0RTCsfwZdvw) for additional insights.
    - `@daymanfan` pointed out the relevance of a [cookbook tutorial](https://cookbook.openai.com/examples/assistants_api_overview_python) to the video mentioned by `@jmtqjmt`.


        

---

## [MLOps @Chipro](https://discord.com/channels/814557108065534033) Discord Summary

Only 1 channel had activity, so no need to summarize...

**MLOps @Chipro Channel Summaries**

### â–· Channel: [events](https://discord.com/channels/814557108065534033/869270934773727272) (2 messages): 

- **Webinar: AI & IIoT Unlocking Industry 4.0**: User `@kirstenl` announced a webinar happening on *November 29, 2023*, at *12PM ET*. Speakers Seth Clark and Brad Munday from Modzy will discuss **edge AI in digital transformation**, the role of MQTT, reference architectures and more. The webinar is aimed at **ML / AI Engineers, IoT engineers, industrial engineers, application engineers**. [Registration Link](https://events.teams.microsoft.com/event/bc5ff964-10c3-4b3b-bd79-47a9c454085c@289b7f80-e16b-4fbe-a571-d8d012a775f1)
- **Webinar: Breaking Down the Economics of LLMs in Production**: User `@idan_benram_62348` posted about a webinar set for *December 5th*, at *7:00 PM GMT*. The webinar will focus on the **economics of LLM deployments (cloud vs. on-premise)**, LLM cost structures, optimizing LLM usage for balance between speed and cost-efficiency, and measuring the unit economics of your LLM application. The webinar is ideal for **business leaders and IT professionals** seeking scalable, cost-effective AI solutions. [Registration Link](https://bit.ly/LLMS_webinar_Tickets)
        

---

## [Ontocord (MDEL discord)](https://discord.com/channels/1147858054231105577) Discord Summary

Only 1 channel had activity, so no need to summarize...

**Ontocord (MDEL discord) Channel Summaries**

### â–· Channel: [general](https://discord.com/channels/1147858054231105577/1147858055095140475) (1 messages): 

- **Discussion about Infrastructure Channel**: User `@rvencu` suggested creating an infrastructure channel to discuss related needs.
        

---

## [AI Engineer Foundation](https://discord.com/channels/1144960932196401252) Discord Summary

Only 1 channel had activity, so no need to summarize...

**AI Engineer Foundation Channel Summaries**

### â–· Channel: [general](https://discord.com/channels/1144960932196401252/1144960932657758210) (1 messages): 

- **Tonic_1's Suggestion for Use of Allen AI Tulu Model**: `@tonic_1` suggests members create a free app using the **Agent Factory / Agent Builder** app with the Allen AI Tulu model. It hasn't been made fully compatible with agent protocol yet, but should still serve the purpose. He shared a [link to the model](https://huggingface.co/spaces/TeamTonic/AgentTulu) for users interested in this project.
        

---
The Perplexity AI Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

---
The YAIG (a16z Infra) Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.