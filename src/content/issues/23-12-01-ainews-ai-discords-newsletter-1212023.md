---
id: d52ac8e9-69fe-4e1f-9f0d-1ab17f30686e
title: AI Discords Newsletter  12/1/2023
date: '2023-12-01T17:56:50.865739Z'
original_slug: ainews-ai-discords-newsletter-1212023
description: >-
  Extensive discussions in the **OpenAI** Discord community highlighted user
  experiences and challenges with **ChatGPT** and **GPT-4**, including
  performance issues, waitlist frustrations, and usage limits. A key focus was
  on GPT-4's capabilities in image analysis and its integration into daily life
  as a personal assistant, alongside concerns about ethical considerations and
  technical problems such as saving errors and API inconsistencies.
tags:
  - openai
  - slab
  - hugging-face
  - chatgpt
  - chatgpt-3.5
  - chatgpt-4
  - gpt-4
  - prompt-engineering
  - image-analysis
  - api-usage
  - subscription-management
  - ethical-considerations
  - personal-assistant
  - software-development
  - learning-techniques
  - user-experience
  - troubleshooting
companies:
  - openai
  - slab
  - hugging-face
models:
  - chatgpt
  - chatgpt-3.5
  - chatgpt-4
  - gpt-4
topics:
  - prompt-engineering
  - image-analysis
  - api-usage
  - subscription-management
  - ethical-considerations
  - personal-assistant
  - software-development
  - learning-techniques
  - user-experience
  - troubleshooting
---


<!-- buttondown-editor-mode: plaintext -->[TOC] 


## [OpenAI](https://discord.com/channels/974519864045756446) Discord Summary

- Extensive dialogues across several channels focused on using and optimizing OpenAI's AI models, specifically, **ChatGPT and GPT-4**, for different applications. Users often compared performance, shared experiences (*"Despite positive feedback, he wondered if a better AI model exists for Python and Flask programming"*), and offered suggestions for better prompt engineering (*"These guidelines emphasise clear, non-repetitive and well-defined instruction giving, understanding AI capabilities, and open communication with the AI"*).

- Notable discussion on *AI integration in daily life*, with vision of AI as a personal assistant or learning companion, proactive AI interaction, potential challenges and ethical considerations. Similarly, AI use cases for enhancing personal growth, productivity, and learning strategies using OpenAI and other AI resources were actively discussed.

- Several concerns and technical issues raised by users, such as image analysis through GPT, saving errors, reading encrypted information, usage cap, waiting list frustrations, login and account issues. A notable comment includes *"Users `@rubi747`, `@abgslayer`, and `@superstar3244` reported issues with usage limits on the OpenAI API despite apparently having balances in their accounts."*

- AI's proficiency in tasks beyond text generation, notably examining and understanding images, was discussed. A quotation that stands out is "*`@donald_23__11175` expressed interest to know if OpenAI's [ChatGPT-4] could analyze images, specifically spotting weak points in dating profile images such as hair styles or expressions.*"

- Lastly, there was community interaction with survey invitations, guidelines for prompt engineering, question formulation and usage policies, as well as an ongoing debate about the AI's ethics and usage restrictions, contributing towards a vibrant discussion atmosphere across channels.

**OpenAI Channel Summaries**

### ‚ñ∑ #[ai-discussions](https://discord.com/channels/974519864045756446/998381918976479273) (104 messages): 
        
        - **ChatGPT as a Python Software Assistant**: `@taholmes160` shared his experience of using **ChatGPT 3.5 and 4.0** for Python software development. Despite positive feedback, he wondered if a better AI model exists for Python and Flask programming, sparking discussion among users like `@HeatOn`, `@eskcanta` and `@webhead`.
        
- **AI Integration in Daily Life**: Users `@fettywhap` and `@exh0rt` pondered over the concept of AI as an integral part of daily life. They envisioned it as a **personal assistant** or **learning companion**, interacting proactively with the user. They also discussed potential **challenges and ethical considerations**, such as fostering dependence or isolation.

- **Exploring AI Use Cases and Learning Process**: `@fettywhap` and `@exh0rt` engaged in an in-depth discussion on how to leverage AI (like **OpenAI**) for personal growth, learning, and productivity. Key strategies highlighted include analyzing learning habits, implementing efficient **learning techniques**, and **prompt engineering**.

- **AI in Biomedical Sciences Study Survey**: `@alvaromartinezmateu` invited the community to participate in a survey exploring public perception of AI applications in biomedical sciences.

- **OpenML and Other Resources**: `@severus_27` shared a link ([*OpenML guide*](https://www.openmlguide.org/)) as a resource for AI enthusiasts to learn from various open-source resources and free materials such as books, courses, papers, guides and more. Users also discussed potential issues with other AI technologies like Slab and Hugging Face.
  
- **Artificial Image Generation**: User `@kelvin_zero` commented on the limitations of AI image generation, stating that it couldn't generate a snake swallowing a fireball. His comment was accompanied by a link to an image.


### ‚ñ∑ #[openai-chatter](https://discord.com/channels/974519864045756446/977697652147892304) (242 messagesüî•): 
        
        - **Performance Comparison between GPT Versions**: User `@mathy_h` mentioned experiencing worsening performance with **GPT-4** over time, pointing towards slower response times and fewer correct answers. User `@foxabilo` contradicted this, stating that GPT-4 is more powerful and has faster response times (from 4-5 tokens per second at launch to 40-50 tokens per second currently).
  
- **Issues with GPT's Response Quality**: Several users pointed out recent quality issues with **GPT-4**. `@enigmaemmy` mentioned that GPT-4 has become "dumber". `@cook_sleep` complained about GPT-4's inability to understand a simple question and design a computing program for it. There was a discussion on how different structures and clarity of prompts can affect the model's output.

- **Waitlist for GPT-4**: Users `@megawhat2015` and `@vincentdecod3rs` expressed frustration over the waitlist for GPT4. `@captainsonic` and `@satanhashtag` responded that there is currently no estimated time of arrival for members to gain access and they should be patient. 

- **Utilizing ChatGPT4 for Professional Tasks**: User `@cirus2390` reported an error encountered at their organization after a security update had allowed them to use ChatGPT4. User `@satanhashtag` suggested solutions like disabling the proxy or trying different browsers.

- **First Anniversary of ChatGPT**: Numerous users wished **ChatGPT** a happy first birthday. They reflected on the AI's improvements and shared their anticipation for future developments.


### ‚ñ∑ #[openai-questions](https://discord.com/channels/974519864045756446/974519864045756454) (158 messagesüî•): 
        
        - **Subscription Cancellations and Waitlist**: User `@feedes` asked about the effect of cancelling and then resubscribing to their ChatGPT Plus subscription. As no firm answer was given, the common consensus was to avoid cancellation due to a long waitlist for new subscriptions.

- **Building a Chatbot with Link Generation Capability**: User `@elevansk` asked for advice on building a chatbot that, in addition to generating answers, could also provide relevant Internet links for enhancing user learning experience.

- **Usage Quotas and Errors**: Users `@rubi747`, `@abgslayer`, and `@superstar3244` reported issues with usage limits on the OpenAI API despite apparently having balance in their accounts. They were advised to get in touch with support for further assistance.

- **Troubleshooting Extension-Related Issues**: Users `@solbus` and `@signate` engaged in a lengthy troubleshooting session to address apparent issues with the ChatGPT web interface, which was not functioning as expected on certain browsers and possibly due to VPN or network filter issues.

- **Custom GPT and API Actions**: User `@8020` reported difficulties making API "actions" work with custom GPTs, noting inconsistent behavior and empty responses from the API. User `@bombenstein` asked for clarifications on the Python API's error-handling mechanisms. In both cases, users were advised to use the developer channels or to wait for further support responses.

- **Account and Login Issues**: User `@nic0m0d` raised concerns regarding difficulties in changing authentication methods for their OpenAI account, raising a broader issue about the inflexibility of account settings and practices.

_Note: No relevant URLs or blog posts were shared in the dialogues provided._


### ‚ñ∑ #[gpt-4-discussions](https://discord.com/channels/974519864045756446/1001151820170801244) (37 messages): 
        
        - **GPT Analyzing Images**: User `@jungle_jo` expressed concern about his custom GPT's inability to analyze provided example images before producing new images. They shared that even with given instructions, the model fails to examine the provided images.
- **GPT Saving Errors**: User `@tman42` brought up the issue of encountering consistent saving errors while updating their GPT, seeking if others are experiencing the same problem.
- **GPT Use for Encrypted Information**: A detailed discussion was provoked by `@toby66_22688`'s inquiry about using GPT for reading and extracting information from passports and visas. While acknowledging the importance of privacy protection, `@toby66_22688` emphasized that as a travel agency they have necessary customer permission to process such information. However, `@martinr_33972` and `@drcapyahhbara` offered opposing views because of security concerns and potential data breach risks on platforms like OpenAI's ChatGPT.
- **Usage Cap Queries**: User `@_vincent32` questioned why the usage of his self-built GPT playground was also restricted despite it supposedly having no usage cap, after his GPT-4 reached the usage limit.  
- **Potential of Custom GPT for Non-Paying Users**: In a discussion between `@whiffleball.` and `@elektronisade`, it was clarified that the benefits of a custom GPT created using the API can indeed be extended to non-paid users. However, it was noted that the API itself is a paid service, but the possibility of charging for access was explored. 
- **Image Analysis Capabilities**: `@donald_23__11175` expressed interest to know if OpenAI's ChatGPT-4 could analyze images, specifically spotting weak points in dating profile images such as hair styles or expressions. User `@satanhashtag` affirmed that the analysis can be done using ChatGPT-4.
- **Unavailability of Plugin Store**: User `@ardi83` reported that they couldn't find the plugin store in their GPT interface and sought help regarding the same.
- **Human Verification Requests**: User `@kibbyd.` complained about being frequently asked to confirm being human despite being a paid user. `@elektronisade` and `@satanhashtag` suggested it might be due to certain factors on the user's system that give an appearance of a bot, and recommended testing with another browser.


### ‚ñ∑ #[prompt-engineering](https://discord.com/channels/974519864045756446/1046317269069864970) (36 messages): 
        
        - **Prompt Engineering Guidelines**: User `@exh0rt` synthesized a detailed list of guidelines for better prompt engineering from the previous discussions of GPT chats and input from other users. These guidelines emphasise clear, non-repetitive and well-defined instruction giving, understanding AI capabilities, and open communication with the AI. `@eskcanta` further added inputs and suggestions, emphasizing the need for instructing the AI to explain its understanding to aid in conflict resolution.

- **Conversation Roleplay**: User `@eskcanta` shared a novel approach to instructing the AI by making it assume a specific role (e.g., a friend named John) to inspect and provide feedback on the user's prompts in an interactive manner. `@exh0rt` felt this was an intriguing path to explore.

- **Sharing Prompts**: In ongoing interaction, `@exh0rt` expressed intention to share the v4 of a new prompt he's working on for feedback but also suggested not to clog the chat. In response to this, `@eskcanta` encouraged making a separate thread for it.

- **Death Battle Queries**: User `@gentleman_crow` expressed difficulty getting AI to answer hypothetical death battle situations between characters. `@solbus` reminded that OpenAI's usage policies restricts violent content.

- **Concerns and Inquiry About OpenAI Fine-Tuning**: `@adx2061` expressed frustration with creating gpt instructions, while `@rez0` posed a question about the effectiveness of OpenAI's fine tuning and how many examples were needed to gain effectiveness.


### ‚ñ∑ #[api-discussions](https://discord.com/channels/974519864045756446/1046317269069864970) (36 messages): 
        
        - **GPT Instruction Guidelines**: In a discussion sparked by `@exh0rt`, the contributors (`@eskcanta` and `@exh0rt`) discussed strategies for providing instructions to OpenAI's GPT models. Key takeaways included avoiding conflicting and repetitive instructions, asking the AI to illuminate any instruction conflicts, allowing the AI 'to talk back' for conflict resolution, and being clear about expected behavior and outcomes. There was also an emphasis on using clear, specific language and avoiding jargon.  


- **Interactive Dialogue with GPT**: `@exh0rt` sought ways to make the AI 'talk back' for better interaction. The discussion, led with `@eskcanta`, touched on strategies such as telling the AI to speak like a certain character and encouraging the AI to ask clarifying questions. 


- **Question Formatting**: `@exh0rt` expressed uncertainty about how to determine and implement the best format for questions when working with GPT. `@eskcanta` advised first having a clear understanding of what the user wants the model to do before exploring different question formats.


- **Violence in AI Response**: User `@gentleman_crow` presented an issue with GPT-3.5's responses regarding violent content, to which `@solbus` reminded of OpenAI's usage policies prohibiting violent content across all services.


- **Fine-Tuning OpenAI GPT**: A user `@rez0` queried about the efficiency of OpenAI's fine-tuning, questioning if a few examples were sufficient or if hundreds were necessary for effectiveness. The question remained unanswered in the provided content.


        

---

## [Nous Research AI](https://discord.com/channels/1053877538025386074) Discord Summary

- Discussions about **Machine Learning Models with Knowledge Graphs**, with `@euclaise` sharing a [paper](https://arxiv.org/pdf/2210.15497.pdf) on the subject and `@max_paperclips` suggesting the use of **Graph Neural Networks (GNNs)** to simplify graph lookups when combined with *Reformulated Adjusted Google PageRank (RAG)* and an external datastore.
- In-depth conversations on **AI/ML career paths**, motivations, and challenges with users like `@teknium` and `@coffeebean6887` sharing their stories and `@jaisel` expressing concerns about career saturation. Videos on related topics also shared by `@pradeep1148` and `@jaisel`.
- Coverage on the performance of multiple **AI models** like *hf-causal-experimental*, **Deepseek 67b**, **Qwen 72b** on systems of various configurations. Models and tasks expertise breakdown provided by `@tokenbender` and thoughts on bot post-processing of performances by `@gabriel_syme`.
- A range of **interesting links** shared, spanning topics from *StableLM Model Size* to *NVIDIA's Superchip for Recommenders and GNNs*. Discussion was also had on topics like Vector Quantization, Elo weirdness's impact on LLM rankings, and speculations around **GPT-4**.
- **Benchmarks and Model Evaluations** emerging as a hot topic, particularly between **Hermes 2.5, Hermes 2, Qwen 72b, and Deepseek 67b**. `@teknium` shared initial comparative benchmark data between these models. Introduction of a new dataset called **HelpSteer**, potential use of multi-language models and speculation over **OpenAI's Compute Capability** being further points of discussion.
- Queries and discussions about **Training Decoder Only Models**, PC Hardware for machine learning, enabling GPU in LM Studio, and experiences with **OpenHermes 2.5 Finetuning** in the context of llms. A full finetune example config shared by `@erikrichardlarson`.
- Clarification about project names and ownership in the **collective cognition** channel, with `@yobibyte` correcting the mention of a project to **Open Access AI Collective** also responsible for **Jackalope**, and `@teknium` confirming the owner as user `<@257999024458563585>`.

**Nous Research AI Channel Summaries**

### ‚ñ∑ #[ctx-length-research](https://discord.com/channels/1053877538025386074/1108104624482812015) (5 messages): 
        
        - **Machine Learning Models with Knowledge Graphs**: User `@euclaise` shared a relevant [paper](https://arxiv.org/pdf/2210.15497.pdf) on domain-specific knowledge graphs to enhance machine learning models.
- **Relevance of Graph Neural Networks (GNNs)**: `@max_paperclips` suggested the possibility of combining *Reformulated Adjusted Google PageRank (RAG)* with an external datastore retrieved as a graph, where **Graph Neural Networks (GNNs)** could simplify graph lookups. However, it is noted that this approach would require more investigation.
- **Executives Function Component over Language Model**: `@spaceman777` emphasized the potential of adding an executive function component or another method of dynamic weights/memory registers over language model-like machines (LLMs). He suggested this could be an answer to the limitations LLMs share with the Oracle of computation theory.
- **Exploitation of Neo4j's Features and Capabilities**: `@spaceman777` expressed his anticipation to see the development of graph-based knowledge versus basic human-designed vector store retrieval hierarchies in the context of *Neo4j*. He also showed great hopes for the advancements in architectural modifications of existing models.
- **Supervisory Systems for Improved Model Performance**: `@maxwellandrews` agreed with the concept of having a supervisory system that can be cross-attended to multiple context regions. This, according to him, might add to the range and efficiency of machine learning models.


### ‚ñ∑ #[off-topic](https://discord.com/channels/1053877538025386074/1109649177689980928) (37 messages): 
        
        - **Career paths and entry into AI/ML**: Users shared their journeys into AI/machine learning, citing obsession with AI, interest in rapidly developing research such as BERT, GPT-2, and an interest from an early age as motivations. Example quotes include `@teknium` saying "*I was obssessed with AI since stable diffusion and then even moreso when chatgpt came out*" and `@coffeebean6887` mentioning how "*Bert got me pretty excited with how everything was building on itself and all the nlp task benchmarks were getting broken and people kept putting out great research on this stuff*‚Äù.
- **Career fears and challenges**: `@jaisel` expressed concerns about career saturation and the presence of more capable individuals in the field. The general sentiment was that one should pursue genuine interests regardless of these fears, as `@teknium` suggested "*If you find something else more interesting you should pursue it instead*".
- **Career paths and motivations**: Users continued to discuss their career paths and motivations, with `@max_paperclips` mentioning a long-standing childhood interest in AI as a driving factor, and `@felixultimaforeverromanempire` sharing their work and educational journey focused on AI. An important point raised was the need for financial motivation in AI, as reflected in `@felixultimaforeverromanempire`'s advice, "*the impetus about AI is making money*."  
- **Video links shared**: `@pradeep1148` and `@jaisel` shared a couple of YouTube videos. The videos' content was not specifically discussed in the messages.
    - [video 1](https://www.youtube.com/watch?v=FmB6QBVvL-Q) 
    - [video 2](https://www.youtube.com/watch?v=uEl2KUZ3JWA&t=1329s)


### ‚ñ∑ #[benchmarks-log](https://discord.com/channels/1053877538025386074/1131747216244092928) (9 messages): 
        
        - There are performances of multiple **AI models** shared, for different systems with various configurations:
  - *hf-causal-experimental* (pretrained=deepseek-ai/deepseek-llm-67b-base,use_accelerate=True), with different tasks and metrics. The results seem varied depending on the tasks and they tested it against multiple tasks, like `boolq`, `arc_challenge`, `arc_easy`, `openbookqa`, `winogrande` etc. They also shared *the benchmarks* for the bigbench tasks like `bigbench_causal_judgement`, `bigbench_disambiguation_qa`, etc.
  - Performance results for **AGIEval and GPT4ALL** are posted by `@teknium` for **Deepseek 67b** and **Qwen 72b**. 'Deepseek 67b' scored 74.87 on GPT4ALL and 36.83 on AGIEval; 'Qwen 72b' scored 72.89 on GPT4ALL and 42.74 on AgieEval.
- `@tokenbender` explains the areas of expertise required for understanding different models and tasks, such as: 
  - Hellaswag for sentence completion ability, 
  - ARC for reasoning and nuance, 
  - MMLU for world knowledge and problem-solving, 
  - MT Bench for multi turn chat. 
  - They also mentioned the need to understand AGIEval and GPT4ALL.
- The idea of creating a **bot for post-processing the performances** suggested by `@gabriel_syme`.
- `@teknium` furthermore suggests creating a **finetune that creates a new form of MT_Bench**, effectively setting up an automated chatbot arena for judging two models against each other.


### ‚ñ∑ #[interesting-links](https://discord.com/channels/1053877538025386074/1132352574750728192) (14 messages): 
        
        - **StableLM Model Size Discussion**: `@teknium` asked whether stableLM is 2.6b or 3.6b. `@atgctg` provided a [Google Doc link](https://docs.google.com/document/d/1tza0OIdTZNNjTqhkWZLRC9ha9Sp7lumGF5ytthx_Ozw/edit) and `@euclaise` mentioned that Hugging Face states it as **2.8B**.
- **Improvements in LLaMA**: `@metaldragon01` shared a [Reddit post](https://www.reddit.com/r/LocalLLaMA/comments/188197j/80_faster_50_less_memory_0_accuracy_loss_llama/) discussing improvements in LLaMA, with `@main.ai` commenting on the peculiar double transpose in their attention implementation.
- **NVIDIA's Superchip for Recommenders and GNNs**: `@lightningralf` posted a [blog post](https://developer.nvidia.com/blog/one-giant-superchip-for-llms-recommenders-and-gnns-introducing-nvidia-gh200-nvl32/) about NVIDIA's new superchip for Recommenders and GNNs.
- **Adept AI's Open Demos**: `@makya` commented on [Adept AI](https://adept.ai) opening up sign-ups for demos and experiments.
- **Vector Quantization Discussion**: `@danielpgonzalez` commented on his first-time reading about vector quantization and how he appreciated the topic being shared.
- **Impact of Elo Weirdness on LLM Rankings**: `@cs2716` posted a [Twitter link](https://twitter.com/CohereForAI/status/1730527365774675989) discussing how Elo weirdness affects LLM rankings.
- **Interesting About GPT-4**: `@tsunemoto` shared an interesting [Twitter post](https://vxtwitter.com/aymericroucher/status/1730636318592414152?s=46&t=stOPrwZiN_fxSK0RuC8Flg) about GPT-4.


### ‚ñ∑ #[general](https://discord.com/channels/1053877538025386074/1149866623109439599) (171 messagesüî•): 
        
        - **Benchmarks**: `@teknium` highlighted the benchmarks of **Hermes 2.5 vs Hermes 2 Performance**. They explained that bigbench and agieval were used because of their use in the orca paper. Truthfulqa was chosen since it runs faster and is on the hf leaderboard. [Discussion Link](https://discord.com/channels/general)
- **Model Evaluations**: Users showed interest in evaluating the performance of new models like **qwen 72b** and **deepseek 67b**. `@teknium` shared initial comparative benchmark data between qwen **72b vs Deepseek 67b**, revealing that they perform better on different benchmark sets. `@makya` offered to evaluate these models against **llama-2 70b**. [Discussion Link](https://discord.com/channels/general)
- **New Dataset**: `@gabriel_syme` shared a new dataset called **HelpSteer** from NVIDIA and suggested its potential use for DPO. `@tokenbender` agreed, also noting its potential use for teaching good data overall due to the provided extra labels. The dataset can be found [here](https://huggingface.co/datasets/nvidia/HelpSteer)
- **Multi-Language Model Usage**: `@r3muxd` asked about the feasibility of using two language models simultaneously. `@euclaise` and `@vatsadev` confirmed it is technically possible but would need the same tokenizer and sufficient VRAM. [Discussion Link](https://discord.com/channels/general)
- **Managing OpenAI Compute**: Users discussed the suspected scale of OpenAI's compute power, noting rumors of a **150k h100 cluster** purchase by Meta and the potential for a **GPT-4 scale model**. They mused about the potential for using this computational power and the supposed cost. [Discussion Link](https://discord.com/channels/general)


### ‚ñ∑ #[ask-about-llms](https://discord.com/channels/1053877538025386074/1154120232051408927) (83 messages): 
        
        - **Training Decoder Only Models**: `@erogol` shared a [paper](https://arxiv.org/pdf/2203.16634.pdf) reporting that training decoder only models without position encoders works fine and asked if anyone had experience with this.
- **PC Hardware Discussion**: `@max_paperclips` inquired about a prebuilt [PC](https://www.umart.com.au/product/g9-core-ryzen-7-7800x3d-geforce-rtx-4090-gaming-pc-55501-74217) for running machine learning models, specifically highlighting the Ryzen 7 and GeForce RTX 4090 hardware. `@ufghfigchv` assured that the Ryzen 7's performance is comparable to an Intel i9, and both agreed that AMD GPUs are problematic due to lack of universal support.
- **PC Hardware Suggestions**: In response to `@max_paperclips`' request for prebuilt PCs, `@giftedgummybee` shared a [link](https://www.jw.com.au/product/gmr-crusader-4090-gaming-pc-i9-13900k-32gb-ddr5-ram-rtx-4090-24g-1tb-nvme-ssd-1200w-windows-11) to a PC with an i9 processor and suggested adding more RAM as necessary.
- **OpenHermes 2.5 Finetuning**: `@spaceman777` asked for comments or experiences with the [OpenHermes-2.5-Mistral-7B-16k model](https://huggingface.co/NurtureAI/OpenHermes-2.5-Mistral-7B-16k) hosted on Hugging Face.
- **Using GPU in LM Studio**: `@felixultimaforeverromanempire` asked how to enable GPU usage in LM Studio, and `@teknium` advised checking the GPU checkbox and entering 9999 for the value.
- **Axolotl Mistral Full Finetuning Config**: In a discussion about finetuning Mistral with Axolotl, `@erikrichardlarson` provided a link to a [full finetune example config](https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/examples/mistral/config.yml).


### ‚ñ∑ #[collective-cognition](https://discord.com/channels/1053877538025386074/1154961277748256831) (2 messages): 
        
        - **Confusion regarding Project Names**: `@yobibyte` clarified their previous mentions of a certain project, correcting it to **Open Access AI Collective** also responsible for **Jackalope**.
- **Project Ownership**: `@teknium` confirmed that these projects are owned by user `<@257999024458563585>`.


### ‚ñ∑ #[memes](https://discord.com/channels/1053877538025386074/1166105758635655270) (1 messages): 

nonameusr: the suffering


        

---

## [LangChain AI](https://discord.com/channels/1038097195422978059) Discord Summary

- Advice sought on **LangChain Agents**, with specific queries on using **AgentExecutorIterator** for JSON input processing during project planning stages (from _@gitmo joe_) and the efficacy of using **CHAT_CONVERSATIONAL_REACT_DESCRIPTION Agent** for web searches via the serp API, which has displayed poor response to complex queries (from _@sid.pocketmail_).
- Discussion on the effectiveness of **fine-tuning a model vs using LangChain** for conducting a progressive conversation raised by _@baller.1337_. 
- Inquiry on **choosing an embedding model** for a chatbot + RAG system, with _@jungle_jo_ questioning the column weights in the [leaderboard](https://huggingface.co/spaces/mteb/leaderboard).
- Solicitation for methods on **importing large data sets** for Q/A purposes into OpenAI API from _@bobi_99349_, with the data being PDFs stored in .bson format, and discussion on using Elastic Search for extraction.
- Community projects and resources shared included a career pathway at [www.smartcareer.ai](https://www.smartcareer.ai/early-access/get-started) (via _@shving90_), the Jupyter AI project presented at AWS re:Invent with the [recorded presentation](https://youtu.be/nDoojNaRhPE?feature=shared) (by _@fortybus_ and _@3coins_), the **hypertion Project** with its [GitHub repository](https://github.com/synacktraa/hypertion) (shared by _@synacktra_), a [YouTube tutorial](https://youtu.be/8wZreQL0V44) providing a basic introduction on OpenGPTs from LangChain (from _@datasciencebasics_), and the [OpenML Guide](https://www.openmlguide.org/) featuring open-source and free resources on AI learning (_@severus_27_). 
- General technical query on customizing the run name without using LLMChain and ChatOpenAI.generate (by _@abhagsain_).
- A reminder on debugging the chain through the server, suggesting first to debug the chain itself prior to writing unit tests / integration tests for the chain (_@veryboldbagel_).

**LangChain AI Channel Summaries**

### ‚ñ∑ #[general](https://discord.com/channels/1038097195422978059/1038097196224086148) (19 messages): 
        
        - **Selecting LangChain Agent**: `@gitmo joe` is seeking advice on which LangChain agent is best suited to process input from a json file during planning stage, and specifically inquired about the potential use of **AgentExecutorIterator**.
- **Fine-tuning vs Using LangChain**: `@baller.1337` posed a question about whether it would be more effective to fine-tune a model or use LangChain for conducting a progressive conversation (collecting user's name, age, etc).
- **Issues with CHAT_CONVERSATIONAL_REACT_DESCRIPTION Agent**: `@sid.pocketmail` reported problems with using the CHAT_CONVERSATIONAL_REACT_DESCRIPTION agent for web searches via the serp api. The agent seems to fail at delivering accurate search results for complex queries.
- **Choosing Embedding Models**: `@jungle_jo` asked for advice on choosing an embedding model for a chatbot + RAG system, focusing on reciting book information. The user was particularly interested in knowing which column should have the most weight in [this leaderboard](https://huggingface.co/spaces/mteb/leaderboard).
- **Importing Data for Q/A**: `@bobi_99349` sought advice on importing a large amount of document files into OpenAI API for question and answering purposes. The data is currently stored as PDFs in .bson format, and using Elastic Search for extraction was estimated to take a couple of days.


### ‚ñ∑ #[langserve](https://discord.com/channels/1038097195422978059/1170024642245832774) (1 messages): 

veryboldbagel: I don't use vscode much, so can't help with setting it up -- but perhaps anyone else here that's familiar with vscode could help? Also if you can I would suggest first trying to debug the chain itself instead of debugging the chain through the server -- the same approach can be useful for writing unit tests / integration tests for the chain that'll be exposed by the server


### ‚ñ∑ #[langchain-templates](https://discord.com/channels/1038097195422978059/1170025009960456282) (1 messages): 

abhagsain: <@1072591948499664996> How to customize the name of the run without using LLMChain. I'm simply using ChatOpenAI.generate


### ‚ñ∑ #[share-your-work](https://discord.com/channels/1038097195422978059/1038097372695236729) (5 messages): 
        
        - **AI Smart Career Start**: `@shving90` shared a link to a career defining pathway from [www.smartcareer.ai](https://www.smartcareer.ai/early-access/get-started) which provides opportunities in smart career advancement.
- **Jupyter AI Presentation at AWS re:Invent**: `@fortybus` and his teammate `@3coins` presented a project named Jupyter AI, built on LangChain, at AWS re:Invent. The recording of the presentation can be found [here](https://youtu.be/nDoojNaRhPE?feature=shared).
- **hypertion Project**: `@synacktra` introduced a project named hypertion and shared the GitHub repository [link](https://github.com/synacktraa/hypertion). The project aids in schema creation and invocation based on a function's signature or metadata.
- **OpenGPTs from LangChain for Complete Beginners**: `@datasciencebasics` shared a [YouTube link](https://youtu.be/8wZreQL0V44) that provides a first look at OpenGPTs from LangChain and is suitable for complete beginners.
- **OpenML Guide**: `@severus_27` shared the [OpenML Guide](https://www.openmlguide.org/), a resource that embraces open-source and free resources and offers a wealth of information related to AI advancements and learning resources.


### ‚ñ∑ #[tutorials](https://discord.com/channels/1038097195422978059/1077843317657706538) (1 messages): 
        
        datasciencebasics: OpenGPTs FROM LangChain ü¶úüîó | FIRST LOOK | FOR Complete Beginners
https://youtu.be/8wZreQL0V44


        

---

## [Latent Space](https://discord.com/channels/822583790773862470) Discord Summary

- Participants shared useful resources related to AI coding:
    - `@slono` linked the **OpenAI Code Review Prompt**, discussing the reconciliation of various self aspects. (*"[Code Review Prompt](https://chat.openai.com/share/0a318748-5849-42d8-aff4-5b2d90303674)"*)
    - `@coffeebean6887` pointed out **Emad's activity on Reddit**, providing a link to a significant comment. (*"[Emad's Comment](https://www.reddit.com/r/StableDiffusion/comments/186rwji/comment/kbalfk7/?context=3)"*)
- The searchability of the name '**GPT Assistant**' was questioned by user `@slono`.
- Language translation service discussion unfolded, with users `@mitchellbwright` and `@mitch3x3` expressing **frustration with LangChain**, and `@fanahova` suggesting **Semantic Kernel** as a potential alternative.
- There were technical discussions around hardware optimizations, with `@mitch3x3` and `@coffeebean6887` speculating on the **worthiness of using NVLink for running dual 3090s**.
- A dialogue on AI language models took place; users `@sarav1n` and `@slono` discussed the need for having a **standard specification for running various types of Language Models (LM) across different programming environments**.
- In the #[llm-paper-club] channel, `@eugeneyan` shared a **thread of AI-related academic papers**, providing valuable resource for those interested in current research trends. (*"[Paper Thread](https://x.com/eugeneyan/status/1670271775337480193)"*)

**Latent Space Channel Summaries**

### ‚ñ∑ #[ai-general-chat](https://discord.com/channels/822583790773862470/1075282825051385876) (22 messages): 
        
        - **Code Review Prompt by OpenAI**: User `@slono` shared the link to a code review prompt and commented about reconciling different aspects of self. 
    - [Code Review Prompt](https://chat.openai.com/share/0a318748-5849-42d8-aff4-5b2d90303674)
- **Emad on Reddit**: User `@coffeebean6887` noted Emad's activity on Reddit and provided a link to a specific comment.
    - [Reddit User Emad](https://www.reddit.com/user/emad_9608/)
    - [Emad's Comment](https://www.reddit.com/r/StableDiffusion/comments/186rwji/comment/kbalfk7/?context=3)
- **Name of GPT Assistant**: `@slono` expressed that 'GPT assistant' as a name for the chatbot is difficult to google for.
- **Alternatives to LangChain**: Users `@mitchellbwright` and `@mitch3x3` noted frustrations with LangChain, and `@fanahova` suggested Semantic Kernel as an alternative.
- **NVLink for 3090s**: Users `@mitch3x3` and `@coffeebean6887` discussed if NVLink is worth it for running dual 3090s. `@coffeebean6887` suggested to skip it unless building a bigger rig and stressed the importance of running them at pcie 4.0 x8.
- **Standard Spec for Language Model (LM)**: Users `@sarav1n` and `@slono` discussed the necessity of a standard specification for running different types of LMs across various programming languages.


### ‚ñ∑ #[llm-paper-club](https://discord.com/channels/822583790773862470/1107320650961518663) (1 messages): 

eugeneyan: here‚Äôs the first dozen or so papers in thread form: https://x.com/eugeneyan/status/1670271775337480193


        

---

## [Alignment Lab AI](https://discord.com/channels/1087862276448595968) Discord Summary

- **Admin availability request** by `@zolandinho` in general chat, prompting a brief conversation within the guild.
- Extended discussion on the **status of project launches and publishing models** led by `@ufghfigchv`, with other participants in the discussion.
- *Speculation and inquiry* around possible future **token considerations**, spurred by `@bdog1741`, with multiple guild members engaged in the conversation.
- `@lightningralf` comments on the **cryptocurrency bull run** predicting an extreme scenario in the next year to a year and a half.
- Concerns over the **quality of the 'no_robots' Dataset** brought up by `@imonenext` with comparisons to alternative solutions such as OASST, without any clear consensus built in the conversation.
- `@turgutluk` observes notable **performance improvements with CRLFT Ablations** when specified name replacements are implemented, intending to conduct human evaluations for a more comprehensive comparison with other models.
- `@giftedgummybee` shares a link to the [lang-uk dataset](https://huggingface.co/datasets/lang-uk/every_prompt) on Hugging Face, proposing a collective interest in **re-augmenting this dataset with GPT-4**.

**Alignment Lab AI Channel Summaries**

### ‚ñ∑ #[general-chat](https://discord.com/channels/1087862276448595968/1095458248712265841) (15 messages): 
        
        - **Admin Availability Request**: `@zolandinho` asked if any admin was available to answer questions.
- **Project's Status Discussion**: The user `@ufghfigchv` clarified that they have been working and publishing models for months in response to a launch query.
- **Token Inquiry**: `@bdog1741` speculated that `@zolandinho` was asking about a possible token, and desired clarity on whether this would be a consideration in the future. There is uncertainty among participants, including `@autometa` and `@ufghfigchv`, regarding what this token might entail.
- **Cryptocurrency Bull Run**: `@lightningralf` remarked on the rising trend of requesting tokens due to a slow-starting cryptocurrency bull run and predicted an extreme scenario in the coming 12 to 18 months.
- **Quality of the 'no_robots' Dataset**: `@imonenext` inquired about the https://huggingface.co/datasets/HuggingFaceH4/no_robots dataset and if it was high-quality following a complaint about its quality. Comparison with OASST is also mentioned but no clear consensus is reached.


### ‚ñ∑ #[oo](https://discord.com/channels/1087862276448595968/1118217717984530553) (5 messages): 
        
        - **CRLFT Ablations Performance**: `@turgutluk` shared that CRLFT, upon replacing "user" and "assistant" with "gpt4-user" and "gpt4-assistant" respectively, appears to improve performance according to the GPT-Eval template they defined. Human evaluation will be conducted for comparison with the top-2 models.
- **Lang-UK Dataset Reaugmentation**: `@giftedgummybee` shared a link to the [lang-uk dataset](https://huggingface.co/datasets/lang-uk/every_prompt) on Hugging Face, and queried if anyone is interested in reaugmenting the dataset with GPT-4.


        

---

## [LLM Perf Enthusiasts AI](https://discord.com/channels/1168579740391710851) Discord Summary

- **Mozilla-Ocho's Llamafile Github Repository** is gaining interest within the community. User `@pantsforbirds` shared the [repository link](https://github.com/Mozilla-Ocho/llamafile) in the #opensource channel, classifying it as *extremely promising*. The mention was further validated by `@thisisnotawill` who found out about llamafile from a [tweet](https://twitter.com/emollick/status/1730113371108782099?t=l0ZYo3a1SQ4RoO08PySDJA&s=19).
- User `@thisisnotawill` expressed a need for an **alternative to gpt 3.5** that is *less censored* for sending prompts. This is not specific for local use but for testing purposes.
- A shared [Google Document](https://docs.google.com/document/d/e/2PACX-1vQD8IlBotGdBxp3BnXkSjk8bNZlPV_0EH9ZA6wHd5dNf-BLSiwXUinvgv8ZoBEnNyTCF-chWO30NRw0/pub) was highlighted by `@joshcho_` in the #general channel, affirming it had received positive feedback on Twitter.
- Due to insufficient information, event details and confirmation of an unspecified news from the #irl and #openai channels could not be included in this summary.

**LLM Perf Enthusiasts AI Channel Summaries**

### ‚ñ∑ #[general](https://discord.com/channels/1168579740391710851/1168579740391710855) (2 messages): 

- `@joshcho_` shared a [Google Document](https://docs.google.com/document/d/e/2PACX-1vQD8IlBotGdBxp3BnXkSjk8bNZlPV_0EH9ZA6wHd5dNf-BLSiwXUinvgv8ZoBEnNyTCF-chWO30NRw0/pub) of interest, and mentioned that it was also shared on Twitter and praised the document.


### ‚ñ∑ #[opensource](https://discord.com/channels/1168579740391710851/1168606773595349082) (4 messages): 
        
        - **Mozilla-Ocho's Llamofile Github Repo**: User `@pantsforbirds` shared a link to a Github repository, [llamafile](https://github.com/Mozilla-Ocho/llamafile), and found it *extremely promising*.  
- **Discussion of Local vs Remote AI Testing Needs**: User `@thisisnotawill` commented that he noticed llamafile via a [tweet](https://twitter.com/emollick/status/1730113371108782099?t=l0ZYo3a1SQ4RoO08PySDJA&s=19). He expressed his need for an **alternative to gpt 3.5** that is *less censored* for sending prompts, not necessarily for local use but just for testing purposes.


### ‚ñ∑ #[irl](https://discord.com/channels/1168579740391710851/1171569983688560732) (1 messages): 

frandecam: Im down- wheres the event?


### ‚ñ∑ #[openai](https://discord.com/channels/1168579740391710851/1171903046612160632) (1 messages): 

dongdong0755: https://x.com/rowancheung/status/1730444618666320128?s=20 so confirmed?


        

---

## [Skunkworks AI](https://discord.com/channels/1131084849432768614) Discord Summary

Only 1 channel had activity, so no need to summarize...


        

---

## [MLOps @Chipro](https://discord.com/channels/814557108065534033) Discord Summary

Only 1 channel had activity, so no need to summarize...


        

---

## [YAIG (a16z Infra)](https://discord.com/channels/958905134119784489) Discord Summary

Only 1 channel had activity, so no need to summarize...


        

---
The Ontocord (MDEL discord) Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

---
The AI Engineer Foundation Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

---
The Perplexity AI Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.