---
id: MjAyNS0w
title: not much happened today
date: '2025-05-02T05:44:39.731046Z'
description: >-
  **Microsoft** released **Phi-reasoning 4**, a finetuned 14B reasoning model
  slightly behind QwQ but limited by data transparency and token efficiency
  issues. **Anthropic** introduced remote MCP server support and a 45-minute
  Research mode in **Claude**. **Cursor** published a model popularity list.
  **Alibaba** launched **Qwen3-235B** and other Qwen3 variants, highlighting
  budget-friendly coding and reasoning capabilities, with availability on
  **Together AI** API. **Microsoft** also released **Phi-4-Mini-Reasoning** with
  benchmark performance on AIME 2025 and OmniMath. **DeepSeek** announced
  **DeepSeek-Prover V2** with state-of-the-art math problem solving, scaling to
  671B parameters. **Meta AI**'s **Llama** models hit 1.2 billion downloads,
  with new **Llama Guard 4** and **Prompt Guard 2** for input/output filtering
  and jailbreak prevention. **Xiaomi** released the open-source reasoning model
  **MiMo-7B** trained on 25 trillion tokens. Discussions on AI model evaluation
  highlighted issues with the **LMArena leaderboard**, data access biases
  favoring proprietary models, and challenges in maintaining fair benchmarking,
  with suggestions for alternatives like **OpenRouterAI** rankings. *"LMArena
  slop and biased"* and *"61.3% of all data going to proprietary model
  providers"* were noted concerns.
companies:
  - microsoft
  - anthropic
  - cursor
  - alibaba
  - togethercompute
  - deepseek
  - meta-ai-fair
  - xiaomi
  - openrouterai
  - cohere
models:
  - phi-4
  - phi-4-mini-reasoning
  - qwen3-235b
  - qwen3-moe-235b
  - qwen3-moe-30b
  - qwen3-dense-32b
  - qwen3-dense-14b
  - qwen3-dense-8b
  - qwen3-dense-4b
  - qwen3-dense-0.6b
  - qwen2.5-omni-3b
  - deepseek-prover-v2
  - llama
  - llama-guard-4
  - prompt-guard-2
  - mimo-7b
topics:
  - reasoning
  - model-fine-tuning
  - model-evaluation
  - benchmarking
  - model-popularity
  - open-source
  - math
  - model-scaling
  - model-filtering
  - jailbreak-prevention
people:
  - cline
  - reach_vb
  - vipulved
  - akhaliq
  - omarsar0
  - zhs05232838
  - huajian_xin
  - mervenoyann
  - karpathy
  - random_walker
  - sarahookr
  - blancheminerva
  - clefourrier
---



**a quiet day.**

> AI News for 4/30/2025-5/1/2025. We checked 9 subreddits, 449 Twitters and 29 Discords (214 channels, and 4767 messages) for you. Estimated reading time saved (at 200wpm): 453 minutes. Our new website is now up with full metadata search and beautiful vibe coded presentation of all past issues. See https://news.smol.ai/ for the full news breakdowns and give us feedback on @smol_ai!
> 

Microsoft released [Phi-reasoning 4,](https://www.reddit.com/r/LocalLLaMA/comments/1kbvwsc/microsoft_just_released_phi_4_reasoning_14b/) a reasoning finetune of the 14B Phi-4 that is slightly behind QwQ in performance, but lack of transparency around their data and complains of inference-token hungriness limit the excitement around it.

Anthropic launched [remote MCP server support in Claude](https://news.ycombinator.com/item?id=43859536) and an up to 45-min long Research mode.

Cursor released their model popularity list, with not much surprises.

![](https://resend-attachments.s3.amazonaws.com/hM6qEzvvHIVmVdX)

---

# AI Twitter Recap

**Language Models and Releases**
